{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d9fbf9f",
   "metadata": {},
   "source": [
    "# Operaciones con probabilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff3ed56",
   "metadata": {},
   "source": [
    "Una vez que entendemos qu√© representa una probabilidad y c√≥mo se puede interpretar, el siguiente paso natural es analizar **c√≥mo se combinan o se relacionan distintos eventos entre s√≠**.\n",
    "\n",
    "Esto nos lleva a estudiar conceptos fundamentales como la **probabilidad condicional, conjunta y marginal**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a4611",
   "metadata": {},
   "source": [
    "## 1.1. Probabilidad conjunta, condicional y marginal\n",
    "\n",
    "Hasta ahora hemos aprendido a:\n",
    "\n",
    "- Definir un **espacio muestral** $(\\Omega)$, que contiene todos los **posibles resultados** de un experimento.\n",
    "- Considerar subconjuntos de $(\\Omega)$ como **eventos**, organizados en una estructura llamada $(\\sigma)$-√°lgebra.\n",
    "- Asignar valores de **probabilidad** a esos eventos mediante funciones que cumplen ciertos principios (como los axiomas de Kolmog√≥rov).\n",
    "- Interpretar esos valores bajo los enfoques **frecuentista** y **bayesiano**.\n",
    "\n",
    "Este marco nos permite describir eventos **individuales**, pero tambi√©n **eventos compuestos**: por ejemplo, cuando dos condiciones ocurren a la vez, o una depende de otra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8799e9",
   "metadata": {},
   "source": [
    "##### ¬øQu√© nos permite considerar eventos compuestos?\n",
    "\n",
    "La clave est√° en la $(\\sigma)$-√°lgebra:\n",
    "\n",
    "> Al definir el espacio de eventos como una $(\\sigma)$-√°lgebra, garantizamos que podemos operar con ellos de forma l√≥gica y estructurada:\n",
    ">\n",
    "> - unir eventos $(A \\cup B)$\n",
    "> - tomar complementos $(A^c)$\n",
    "> - y tambi√©n **intersecciones** como $(A \\cap B)$, que representan **eventos conjuntos**.\n",
    "\n",
    "Esto no solo nos permite construir descripciones m√°s ricas de situaciones, sino que nos habilita a hacer **operaciones de probabilidad** sobre m√∫ltiples eventos.\n",
    "\n",
    "A continuaci√≥n, exploraremos tres operaciones fundamentales:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3b2e96",
   "metadata": {},
   "source": [
    "### 1.1.1. Probabilidad conjunta\n",
    "\n",
    "La **probabilidad conjunta** mide la probabilidad de que **dos eventos ocurran al mismo tiempo**.\n",
    "\n",
    "Se denota como:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(A \\cap B)\n",
    "$$\n",
    "\n",
    "o, si el contexto lo permite, simplemente $\\mathbb{P}(A, B)$.\n",
    "\n",
    "```{admonition} Ejemplo\n",
    ":class: tip\n",
    "\n",
    "Si $(A = \\{\\text{llover}\\})$ y $(B = \\{\\text{llevar paraguas}\\})$,\n",
    "entonces $(\\mathbb{P}(A \\cap B))$ representa la probabilidad de que **llueva y lleves paraguas** el mismo d√≠a.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501ce8c3",
   "metadata": {},
   "source": [
    "### 1.1.2. Probabilidad condicional\n",
    "\n",
    "La **probabilidad condicional** responde a la pregunta:\n",
    "\n",
    "> ¬øCu√°l es la probabilidad de que ocurra \\(A\\) si ya sabemos que ocurri√≥ \\(B\\)?\n",
    "\n",
    "Se define como:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(A \\mid B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)} \\quad \\text{si } \\mathbb{P}(B) > 0\n",
    "$$\n",
    "\n",
    "```{admonition} Ejemplo\n",
    ":class: tip\n",
    "\n",
    "Si $(\\mathbb{P}(\\text{llover y llevar paraguas}) = 0.3 )$\n",
    "y $(\\mathbb{P}(\\text{llevar paraguas}) = 0.5)$,\n",
    "entonces:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(\\text{llover} \\mid \\text{llevar paraguas}) = \\frac{0.3}{0.5} = 0.6\n",
    "$$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b66e0c",
   "metadata": {},
   "source": [
    "### 1.1.3. Probabilidad marginal\n",
    "\n",
    "La **probabilidad marginal** es la probabilidad de un evento **sin condicionar** en ning√∫n otro.\n",
    "\n",
    "Cuando trabajamos con variables m√∫ltiples, podemos obtener la marginal de una variable ‚Äúresumiendo‚Äù la informaci√≥n sobre las otras.\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(A) = \\sum_{b} \\mathbb{P}(A, B=b)\n",
    "$$\n",
    "\n",
    "En el caso continuo:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(A) = \\int \\mathbb{P}(A, B)\\, dB\n",
    "$$\n",
    "\n",
    "```{admonition} Nota\n",
    ":class: note\n",
    "\n",
    "La marginal es √∫til cuando queremos concentrarnos en un solo evento o variable, ignorando otras que tambi√©n est√°n en juego.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd15bf0",
   "metadata": {},
   "source": [
    "## 1.2. Reglas derivadas de la probabilidad\n",
    "\n",
    "Una vez que hemos definido formalmente la **probabilidad condicional**, podemos deducir tres reglas fundamentales que se utilizan constantemente en modelado probabil√≠stico.\n",
    "\n",
    "Estas reglas no son nuevos axiomas, sino **consecuencias directas** de combinar:\n",
    "\n",
    "- Los **axiomas de Kolmog√≥rov**, especialmente:\n",
    "\n",
    "  - La aditividad: $P(A \\cup B) = P(A) + P(B)$ si $A \\cap B = \\varnothing$\n",
    "\n",
    "- La **definici√≥n de probabilidad condicional**\n",
    "\n",
    "Veamos cada una:\n",
    "\n",
    "##### üìå Regla de marginalizaci√≥n\n",
    "\n",
    "Se basa en la **aditividad**: si $B$ puede tomar varios valores disjuntos, entonces:\n",
    "\n",
    "$$\n",
    "P(A) = \\sum_B P(A, B)\n",
    "$$\n",
    "\n",
    "Esta regla permite **reducir** una probabilidad conjunta a una **marginal**.\n",
    "\n",
    "---\n",
    "\n",
    "##### üìå Regla de la cadena\n",
    "\n",
    "Viene directamente de _reordenar_ la definici√≥n de probabilidad condicional:\n",
    "\n",
    "$$\n",
    "P(A \\mid B) = \\frac{P(A, B)}{P(B)} \\quad \\Rightarrow \\quad P(A, B) = P(A \\mid B) \\cdot P(B)\n",
    "$$\n",
    "\n",
    "Esta relaci√≥n es fundamental en estructuras secuenciales como los modelos gr√°ficos.\n",
    "\n",
    "Tambi√©n puede escribirse sim√©tricamente:\n",
    "\n",
    "$$\n",
    "P(B, A) = P(B \\mid A) \\cdot P(A)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "##### üìå Regla de la probabilidad total\n",
    "\n",
    "Surge al aplicar **marginalizaci√≥n** sobre la **regla de la cadena**:\n",
    "\n",
    "$$\n",
    "P(A) = \\sum_B P(A, B) = \\sum_B P(A \\mid B) \\cdot P(B)\n",
    "$$\n",
    "\n",
    "Es decir, descomponemos la probabilidad de $A$ en funci√≥n de sus componentes condicionales respecto a $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eedb58",
   "metadata": {},
   "source": [
    "```{admonition} Nota t√©cnica\n",
    ":class: tip\n",
    "\n",
    "En el contexto de probabilidad, usamos la notaci√≥n $P(A, B)$ como abreviatura de $P(A \\cap B)$ (la probabilidad de que ocurran ambos eventos).\n",
    "```\n",
    "\n",
    "> Adem√°s de ser √∫til para calcular probabilidades marginales,  \n",
    "> la **regla de la probabilidad total** tambi√©n puede interpretarse como una **constante de normalizaci√≥n**:\n",
    ">\n",
    "> garantiza que la distribuci√≥n condicional resultante \\( P(A \\mid B) \\) sea **v√°lida**,  \n",
    "> es decir, que **sume 1** al considerar todos los posibles valores de \\(A\\).\n",
    "\n",
    "```{math}\n",
    "\\sum_A P(A \\mid B) = 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d86f301",
   "metadata": {},
   "source": [
    "![](../images/reglas_probabilidad_diagrama.png)\n",
    "\n",
    "**Figura 5.** La definici√≥n de probabilidad condicional permite derivar tres reglas fundamentales: la **regla de la cadena**, la **regla de marginalizaci√≥n** y la **regla de la probabilidad total**. Estas relaciones son la base del razonamiento probabil√≠stico en contextos donde intervienen m√∫ltiples eventos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c122b8",
   "metadata": {},
   "source": [
    "## Ejercicio intuitivo de clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784339b9",
   "metadata": {},
   "source": [
    "![Ejercicio intuitivo de clase](../images/sesion2-ejemintuitivo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e1d432",
   "metadata": {},
   "source": [
    "Podemos preguntarnos:\n",
    "\n",
    "> *¬øCu√°l es la probabilidad de seleccionar una manzana?*\n",
    "\n",
    "> *Dado que elegimos una naranja, ¬øCu√°l es la probabilidad que la caja haya sido la azul?*\n",
    "\n",
    "Notemos que estas probabilidades no las conocemos de antemano. Incluso, notemos que son probabilidades que involucran m√°s de una variable. Sin embargo, tenemos la informaci√≥n necesaria para **inferir estas probabilidades**, no sin antes conocer la regla de la suma (**marginalizaci√≥n**), y la regla del producto (**regla de la cadena**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b93e618",
   "metadata": {},
   "source": [
    "Para obtener estas reglas en nuestro modo intuitivo de estudiar probabilidad, consideremos el caso m√°s general en que tenemos dos variables aleatorias $X$ y $Y$, las cuales pueden tomar los valores $x^i$ para $i=0,\\dots,s$ y $y^j$ para $j=0,\\dots,t$.\n",
    "\n",
    "Supongamos que, de un total de $N$ repeticiones, \n",
    "\n",
    "- en $n_{ij}$ ocasiones obtuvimos $X=x^i$ y $Y=y^j$;\n",
    "- en $c_{i}$ ocasiones obtuvimos $X=x^i$, sin importar el valor de $Y$;\n",
    "- en $r_{j}$ ocasiones obtuvimos $Y=y^j$, sin importar el valor de $X$;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a569e9",
   "metadata": {},
   "source": [
    "De nuestra definici√≥n de probabilidad, tenemos que (suponiendo que $N \\to \\infty$):\n",
    "\n",
    "#### Probabilidad conjunta\n",
    "\n",
    "1. La *probabilidad conjunta* de que $X=x^i$ y $Y=y^j$ es:\n",
    "\n",
    "   $$\n",
    "   p(X=x^i, Y=y^j) = \\frac{n_{ij}}{N}.\n",
    "   $$\n",
    "\n",
    "#### Probabilidad marginal\n",
    "\n",
    "2. La *probabilidad marginal* de que $X=x^i$ sin importar el valor de Y es;\n",
    "   \n",
    "   $$\n",
    "   p(X=x^i) = \\frac{c_{i}}{N}.\n",
    "   $$\n",
    "   \n",
    "   Notemos que $c_i = \\sum_j n_{ij}$, y en este sentido podemos establecer la regla de la suma (*marginalizaci√≥n*):\n",
    "   \n",
    "   $$\n",
    "   p(X=x^i) = \\sum_{j=0}^{t} p(X=x^i, Y=y^j).\n",
    "   $$\n",
    "   \n",
    "   Similarmente, podemos definir la probabilidad marginal $p(Y=y^j)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af1944",
   "metadata": {},
   "source": [
    "#### Probabilidad condicional\n",
    "\n",
    "3. Si en lugar de considerar todos los posibles repeticiones, consideramos solo aquellas para las que $X=x^i$, entonces la fracci√≥n de dichas repeticionesoara las cuales $Y=y^j$, la conocemos como **probabilidad condicional** de $Y=y^j$ dado $X=x^i$, y la escribimos como:\n",
    "\n",
    "   $$\n",
    "   p(Y=y^j | X=x^i) = \\frac{n_{ij}}{c_i}.\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2d2b1a",
   "metadata": {},
   "source": [
    "![Ejercicio intuitivo de clase](../images/sesion2-ejemintuitivoB.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05919198",
   "metadata": {},
   "source": [
    "Podemos observar que la probabilidad conjunta, la podemos escribir como:\n",
    "\n",
    "$$\n",
    "p(X=x^i, Y=y^j) = \\frac{n_{ij}}{N} = \\frac{n_{ij}}{c_i} \\frac{c_{i}}{N} = p(Y=y^j | X=x^i) p(X=x^i),\n",
    "$$\n",
    "\n",
    "dando lugar a la regla del producto (**regla de la cadena**), y dando lugar a la definici√≥n de probabilidad condicional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0095bcd",
   "metadata": {},
   "source": [
    "La **probabilidad condicional** de una variable aleatoria $Y$ condicionada a que conocemos la variable aleatoria $X$ (la probabilidad de $Y$ dado $X$), se define como:\n",
    "\n",
    "$$\n",
    "p(Y|X) = \\frac{p(X, Y)}{p(X)},\n",
    "$$\n",
    "\n",
    "siempre que $p(X)>0$. Si $p(X)=0$, entonces $p(Y|X)$ no est√° definida.\n",
    "\n",
    "La probabilidad condicional es una distribuci√≥n de probabilidad v√°lida, en el sentido que:\n",
    "\n",
    "- $0 \\leq p(Y|X) \\leq 1$, y\n",
    "- $\\sum_{Y} p(Y|X) = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93a4562",
   "metadata": {},
   "source": [
    "#### Regla de la cadena\n",
    "\n",
    "De la definici√≥n de probabilidad condicional, se desprende autom√°ticamente lo que conocemos como **la regla de la cadena** en probabilidad:\n",
    "\n",
    "$$\n",
    "p(X, Y) = p(Y|X) p(X).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e1633",
   "metadata": {},
   "source": [
    "#### Regla de probabilidad total\n",
    "\n",
    "Teniendo a la mano la regla de la cadena, y la marginalizaci√≥n, podemos escribir **la regla de probabilidad total** como:\n",
    "\n",
    "$$\n",
    "p(X) = \\sum_Y p(X | Y) p(Y),\n",
    "$$\n",
    "\n",
    "y se puede entender como una constante de normalizaci√≥n para asegurar que la probabilidad condicional sea **una distribuci√≥n de probabilidad v√°lida**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8cc3bb",
   "metadata": {},
   "source": [
    "```{admonition} Resumen\n",
    ":class: tip\n",
    "\n",
    "- $0 \\leq p(X) \\leq 1$: Definici√≥n de probabilidad (i)\n",
    "- $\\sum_X p(X) = 1$: Definici√≥n de probabilidad (ii)\n",
    "- $p(X) = \\sum_{Y} p(X, Y)$: Marginalizaci√≥n\n",
    "- $p(X, Y) = p(Y | X) p(X) = p(X | Y) p(Y)$: Regla de la cadena\n",
    "- $p(X) = \\sum_Y p(X | Y) p(Y)$: Probabilidad total: marginalizaci√≥n + r. cadena\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3338fd9a",
   "metadata": {},
   "source": [
    "Las preguntas iniciales eran:\n",
    "\n",
    "> *¬øCu√°l es la probabilidad de seleccionar una manzana?*\n",
    " \n",
    "Primero que nada, las probabilidades que tenemos son:\n",
    "\n",
    "<details>\n",
    "  <summary>Descubrir</summary>\n",
    "  \n",
    "$$\n",
    "p(a) = 0.4 = \\frac{2}{5}, \\qquad p(r) = 0.6 = \\frac{3}{5}, \\qquad p(n | a) = \\frac{1}{4}, \\qquad p(m | a) = \\frac{3}{4}, \\qquad p(n | r) = \\frac{3}{4}, \\qquad p(m | r) = \\frac{1}{4}.\n",
    "$$\n",
    "\n",
    "En este sentido, y usando la regla de la probabilidad total:\n",
    "\n",
    "$$\n",
    "p(m) = p(m | a) p(a) + p(m | r) p(r) = \\frac{3}{4} \\times \\frac{2}{5} + \\frac{1}{4} \\times \\frac{3}{5} = \\frac{9}{20}.\n",
    "$$\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e731b5de",
   "metadata": {},
   "source": [
    "> *Dado que elegimos una naranja, ¬øCu√°l es la probabilidad que la caja haya sido la azul?*\n",
    "\n",
    "<details>\n",
    "  <summary>Descubrir</summary>\n",
    "  \n",
    "Ahora, podemos usar la regla de Bayes:\n",
    "\n",
    "$$\n",
    "p(a | n) = \\frac{p(n | a) p(a)}{p(n)}\n",
    "$$\n",
    "\n",
    "de donde ya conocemos $p(n | a)$ y la **previa** $p(a)$. Adicionalmente,\n",
    "\n",
    "$$\n",
    "p(n) = 1 - p(m) = \\frac{11}{20}.\n",
    "$$\n",
    "\n",
    "Por lo cual:\n",
    "\n",
    "$$\n",
    "p(a | n) = \\frac{1}{4} \\times \\frac{2}{5} \\times \\frac{20}{11} = \\frac{2}{11}\n",
    "$$\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240644bd",
   "metadata": {},
   "source": [
    "La respuesta a la segunda pregunta es bastante interesante, y demuestra el proceso fundamental de incorporar evidencia en un problema. \n",
    "\n",
    "- Notemos que, antes de saber qu√© fruta elegimos, **la probabilidad previa** de elegir la caja azul es $p(a) = \\frac{4}{10}$.\n",
    "\n",
    "- Ahora, al incorporar la evidencia de que la fruta que elegimos fue una naranja, observamos que **la probabilidad posterior** de elegir la caja azul disminuy√≥ considerablemente a $p(a | n) = \\frac{2}{11}$.\n",
    "\n",
    "- Lo anterior es intuitivo, dado que la proporci√≥n de naranjas es significativamente m√°s alta en la caja roja ($p(n | r) = \\frac{3}{4}$) que en la caja azul ($p(n | a) = \\frac{1}{4}$).\n",
    "\n",
    "> Por esta bondad de a√±adir informaci√≥n de evidencia a nuestras inferencias es por lo que **la regla de Bayes es tan relevante.**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
