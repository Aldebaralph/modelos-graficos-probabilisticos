
<!DOCTYPE html>


<html lang="es" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Sesi√≥n 2 &#8212; Modelos gr√°ficos probabil√≠sticos</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=47050f13"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/translations.js?v=f85f4cfb"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'modulo1/M1-sesion2';</script>
    <link rel="index" title="√çndice" href="../genindex.html" />
    <link rel="search" title="B√∫squeda" href="../search.html" />
    <link rel="next" title="Sesi√≥n 3" href="M1-sesion3.html" />
    <link rel="prev" title="Sesi√≥n 1" href="M1-sesion1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="es"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Saltar al contenido principal</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Volver arriba</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Advertencia de versi√≥n"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/nodo.png" class="logo__image only-light" alt="Modelos gr√°ficos probabil√≠sticos - Home"/>
    <script>document.write(`<img src="../_static/nodo.png" class="logo__image only-dark" alt="Modelos gr√°ficos probabil√≠sticos - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="B√∫squeda" aria-label="B√∫squeda" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">B√∫squeda</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Modelos gr√°ficos probabil√≠sticos
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">M√≥dulos y recursos</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../introduccion.html">Introducci√≥n</a></li>
<li class="toctree-l1"><a class="reference internal" href="../acuerdos-de-clase.html">Sobre la clase</a></li>
<li class="toctree-l1"><a class="reference internal" href="../herramientas.html">üõ†Ô∏è Herramientas</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">M√≥dulo 1</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="M1-sesion1.html">Sesi√≥n 1</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Sesi√≥n 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="M1-sesion3.html">Sesi√≥n 3</a></li>
<li class="toctree-l2"><a class="reference internal" href="M1-sesion4.html">Sesi√≥n 4</a></li>
<li class="toctree-l2"><a class="reference internal" href="M1-sesion5.html">Sesi√≥n 5</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../recursos-bibliograficos.html">Recursos biliogr√°ficos</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/patymunoz/modelos-graficos-probabilisticos" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Repositorio de origen"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/patymunoz/modelos-graficos-probabilisticos/edit/main/modulo1/M1-sesion2.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/patymunoz/modelos-graficos-probabilisticos/issues/new?title=Issue%20on%20page%20%2Fmodulo1/M1-sesion2.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Abrir un problema"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Descarga esta pagina">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/modulo1/M1-sesion2.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Descargar archivo fuente"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Imprimir en PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Modo de pantalla completa"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="claro/oscuro" aria-label="claro/oscuro" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="B√∫squeda" aria-label="B√∫squeda" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Sesi√≥n 2</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contenido </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#repaso-de-probabilidad">1. Repaso de probabilidad</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#introduccion">1.1. Introducci√≥n</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fundamentos-de-la-teoria-de-probabilidad">1.2. Fundamentos de la teor√≠a de probabilidad</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#espacio-muestral-omega">1.2.1. Espacio muestral <span class="math notranslate nohighlight">\((\Omega)\)</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conjunto-potencia-mathcal-p-omega">1.2.2. Conjunto potencia <span class="math notranslate nohighlight">\(\mathcal{P}(\Omega)\)</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#algebra-s-o-espacio-de-eventos">1.2.3. œÉ-√°lgebra <span class="math notranslate nohighlight">\((S)\)</span> o espacio de eventos</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#funcion-de-probabilidad">1.2.4. Funci√≥n de probabilidad</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#como-se-relacionan-los-conceptos-que-hemos-visto">¬øC√≥mo se relacionan los conceptos que hemos visto?</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#distribucion-de-probabilidad">1.2.5. Distribuci√≥n de probabilidad</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuciones-discretas">1.2.5.1 Distribuciones discretas</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuciones-continuas">1.2.5.1 Distribuciones continuas</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretaciones-de-la-probabilidad">1.2.6. Interpretaciones de la probabilidad</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#enfoque-frecuentista-medir-por-repeticion">Enfoque frecuentista: medir por repetici√≥n</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#enfoque-bayesiano-probabilidades-como-creencias">Enfoque bayesiano: probabilidades como creencias</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilidad-conjunta-condicional-y-marginal">1.2.7. Probabilidad conjunta, condicional y marginal</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#que-nos-permite-considerar-eventos-compuestos">¬øQu√© nos permite considerar eventos compuestos?</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilidad-conjunta">1. Probabilidad conjunta</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilidad-condicional">2. Probabilidad condicional</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilidad-marginal">3. Probabilidad marginal</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#reglas-derivadas-de-la-probabilidad">1.2.8. Reglas derivadas de la probabilidad</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#regla-de-marginalizacion">üìå Regla de marginalizaci√≥n</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#regla-de-la-cadena">üìå Regla de la cadena</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#regla-de-la-probabilidad-total">üìå Regla de la probabilidad total</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#independencia">1.2.9. Independencia</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#simetria">Simetr√≠a</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#alternativa-para-variables">Alternativa para variables</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#independencia-condicional">1.2.10. Independencia condicional</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="sesion-2">
<h1>Sesi√≥n 2<a class="headerlink" href="#sesion-2" title="Link to this heading">#</a></h1>
<section id="repaso-de-probabilidad">
<h2>1. Repaso de probabilidad<a class="headerlink" href="#repaso-de-probabilidad" title="Link to this heading">#</a></h2>
<section id="introduccion">
<h3>1.1. Introducci√≥n<a class="headerlink" href="#introduccion" title="Link to this heading">#</a></h3>
<p>Antes de sumergirnos en el mundo de los <em>modelos gr√°ficos probabil√≠sticos</em>, comprendamos primero algunos de los fundamentos de la teor√≠a de probabilidad, ya que constituye la base formal para este enfoque.</p>
<p>Una forma de visualizar su importancia es observando c√≥mo diferentes perspectivas epistemol√≥gicas y metodol√≥gicas dan lugar a distintos tipos de modelado. En la <strong>Figura 1</strong>, se muestra una distinci√≥n entre dos enfoques principales:</p>
<ul class="simple">
<li><p>El <strong>enfoque determinista</strong>, que se basa en el modelado no probabil√≠sta y utiliza m√©todos donde no interviene el azar.</p></li>
<li><p>El <strong>enfoque estoc√°stico</strong>, que recurre al modelado probabil√≠sta y se sustenta formalmente en la teor√≠a de probabilidad.</p></li>
</ul>
<p>Ambos caminos convergen en aplicaciones pr√°cticas como los <strong>modelos de aprendizaje autom√°tico (ML) y aprendizaje profundo (DL)</strong>. Estos modelos pueden surgir tanto desde una perspectiva determinista como estoc√°stica, aunque es en el enfoque probabil√≠stico donde encontramos herramientas m√°s directas para representar la <em>incertidumbre</em> y tomas decisiones informadas.</p>
<p><img alt="" src="../_images/sesion2-esquema.png" /></p>
<p><strong>Figura 1.</strong> Elaboraci√≥n propia.</p>
</section>
<section id="fundamentos-de-la-teoria-de-probabilidad">
<h3>1.2. Fundamentos de la teor√≠a de probabilidad<a class="headerlink" href="#fundamentos-de-la-teoria-de-probabilidad" title="Link to this heading">#</a></h3>
<p>La teor√≠a de probabilidad nos permite modelar incertidumbre mediante una estructura matem√°tica compuesta por tres elementos: <em>un espacio muestral, un sistema de eventos medibles y una funci√≥n de probabilidad</em>. Formalmente, esta estructura se expresa como la <strong>triple</strong>:</p>
<div class="math notranslate nohighlight">
\[(\Omega, S, \mathbb{P})\]</div>
<hr class="docutils" />
<p>A continuaci√≥n, desglosamos cada uno de estos componentes:</p>
<section id="espacio-muestral-omega">
<h4>1.2.1. Espacio muestral <span class="math notranslate nohighlight">\((\Omega)\)</span><a class="headerlink" href="#espacio-muestral-omega" title="Link to this heading">#</a></h4>
<p>El <strong>espacio muestral</strong> es el conjunto que contiene <strong>todos los posibles resultados</strong> de un experimento aleatorio. Se denota por:</p>
<div class="math notranslate nohighlight">
\[
\Omega
\]</div>
<ul class="simple">
<li><p>Representa <strong>todo lo que puede pasar</strong>.</p></li>
<li><p>Es el punto de partida para definir eventos.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Ejemplo</p>
<p>Si lanzamos un dado de 6 caras, el espacio muestral es:</p>
<p><span class="math notranslate nohighlight">\(\Omega = \{1, 2, 3, 4, 5, 6\}\)</span></p>
</div>
<p>Puedes consultar m√°s <a class="reference external" href="https://en.wikipedia.org/wiki/Probability_space">aqu√≠</a></p>
</section>
<section id="conjunto-potencia-mathcal-p-omega">
<h4>1.2.2. Conjunto potencia <span class="math notranslate nohighlight">\(\mathcal{P}(\Omega)\)</span><a class="headerlink" href="#conjunto-potencia-mathcal-p-omega" title="Link to this heading">#</a></h4>
<p>Es el conjunto de <strong>todos los subconjuntos <em>posibles</em></strong> de <span class="math notranslate nohighlight">\(\Omega\)</span>.</p>
<ul class="simple">
<li><p>Incluye desde el conjunto vac√≠o <span class="math notranslate nohighlight">\(\varnothing\)</span> hasta el conjunto total <span class="math notranslate nohighlight">\(\Omega\)</span>.</p></li>
<li><p>Representa <strong>todas las combinaciones posibles de eventos.</strong></p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Ejemplo</p>
<p>Si <span class="math notranslate nohighlight">\(\Omega={1,2,3}\)</span>, entonces:</p>
<p><span class="math notranslate nohighlight">\(P(\Omega) = \{\varnothing, \{1\}, \{2\}, \{3\}, \{1,2\}, \{1,3\}, \{2,3\}, \{1,2,3\}\}\)</span></p>
</div>
<p>A continuaci√≥n, podemos ver el <strong>conjunto potencia</strong> en la <strong>Figura 2</strong>, representado mediante un diagrama de Hasse.</p>
<p><img alt="" src="../_images/hasse.png" /></p>
<p><strong>Figura 2.</strong> Diagrama de Hasse del conjunto potencia de <span class="math notranslate nohighlight">\({1,2,3}\)</span>. Elaboraci√≥n propia con base en: <a class="reference external" href="https://en.wikipedia.org/wiki/Power_set"><em>Power set</em></a>.</p>
<p>Puedes consultar m√°s <a class="reference external" href="https://en.wikipedia.org/wiki/Power_set">aqu√≠</a>.</p>
</section>
<section id="algebra-s-o-espacio-de-eventos">
<h4>1.2.3. œÉ-√°lgebra <span class="math notranslate nohighlight">\((S)\)</span> o espacio de eventos<a class="headerlink" href="#algebra-s-o-espacio-de-eventos" title="Link to this heading">#</a></h4>
<p>Es una colecci√≥n especial de subconjuntos de <span class="math notranslate nohighlight">\(\Omega\)</span> (es decir, una subcolecci√≥n de <span class="math notranslate nohighlight">\(\mathcal{P}(\Omega)\)</span>) que cumple con tres propiedades clave:</p>
<div class="tip admonition">
<p class="admonition-title">Propiedades del sistema de eventos <span class="math notranslate nohighlight">\(S\)</span></p>
<ol class="arabic simple">
<li><p><strong>Contiene el evento vac√≠o y el evento total</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\varnothing \in S\)</span>: representa el evento que nunca ocurre.</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega \in S\)</span>: representa el evento que siempre ocurre.</p></li>
</ul>
</li>
<li><p><strong>Cerrado bajo uni√≥n</strong>
Si <span class="math notranslate nohighlight">\(\alpha, \beta \in S\)</span>, entonces <span class="math notranslate nohighlight">\(\alpha \cup \beta \in S\)</span>.
Esto permite formar eventos como ‚Äúocurre <span class="math notranslate nohighlight">\(\alpha\)</span> o <span class="math notranslate nohighlight">\(\beta\)</span>‚Äù.</p></li>
<li><p><strong>Cerrado bajo complemento</strong>
Si <span class="math notranslate nohighlight">\(\alpha \in S\)</span>, entonces <span class="math notranslate nohighlight">\(\Omega - \alpha \in S\)</span> (tambi√©n denotado <span class="math notranslate nohighlight">\(\alpha^c\)</span>).
Esto garantiza que tambi√©n podamos trabajar con el evento ‚Äúno ocurre <span class="math notranslate nohighlight">\(\alpha\)</span>‚Äù.</p></li>
</ol>
</div>
<div class="admonition-ejemplo admonition">
<p class="admonition-title">Ejemplo</p>
<p>Si <span class="math notranslate nohighlight">\(\Omega={1,2,3}\)</span>, una posible œÉ-√°lgebra es:</p>
<div class="math notranslate nohighlight">
\[S = \{\varnothing, \{1,2,3\}, \{1\}, \{2,3\}\}\]</div>
<p>Aqu√≠, <span class="math notranslate nohighlight">\(\{2,3\}\)</span> es el complemento de <span class="math notranslate nohighlight">\(\{1\}\)</span>, y viceversa.</p>
</div>
<p>Puedes consultar m√°s <a class="reference external" href="https://en.wikipedia.org/wiki/%CE%A3-algebra#Definition_and_properties">aqu√≠</a>.</p>
</section>
<section id="funcion-de-probabilidad">
<h4>1.2.4. Funci√≥n de probabilidad<a class="headerlink" href="#funcion-de-probabilidad" title="Link to this heading">#</a></h4>
<p>Hasta ahora hemos definido el espacio muestral <span class="math notranslate nohighlight">\((\Omega)\)</span>, que contiene todos los posibles resultados de un experimento, y una œÉ-√°lgebra <span class="math notranslate nohighlight">\((S)\)</span>, que representa los subconjuntos medibles de <span class="math notranslate nohighlight">\((\Omega)\)</span>, es decir, los <strong>eventos</strong> a los que podemos asignar una probabilidad coherente.</p>
<p>Una <strong>funci√≥n de probabilidad</strong> es una regla matem√°tica que asigna a cada evento medible un n√∫mero entre <span class="math notranslate nohighlight">\(0\)</span> y <span class="math notranslate nohighlight">\(1\)</span>, representando <strong>cu√°n probable</strong> es que ese evento ocurra. Formalmente:</p>
<div class="math notranslate nohighlight">
\[\mathbb{P} : S \rightarrow [0, 1]\]</div>
<p>o</p>
<div class="math notranslate nohighlight">
\[0 \leq \mathbb{P}(\text{evento}) \leq 1\]</div>
<p>Para que esta asignaci√≥n tenga sentido y sea consistente con la intuici√≥n, la funci√≥n <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> debe cumplir tres condiciones fundamentales, conocidas como los <strong>axiomas de Kolmog√≥rov</strong>:</p>
<div class="tip admonition">
<p class="admonition-title">Definici√≥n formal</p>
<p>Una funci√≥n <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> es una <strong>probabilidad</strong> sobre el espacio <span class="math notranslate nohighlight">\((\Omega, S)\)</span> si cumple:</p>
<ol class="arabic simple">
<li><p><strong>No negatividad:</strong> <span class="math notranslate nohighlight">\(\mathbb{P}(A) \geq 0\)</span> para todo <span class="math notranslate nohighlight">\(A \in S\)</span></p></li>
<li><p><strong>Normalizaci√≥n:</strong> <span class="math notranslate nohighlight">\(\mathbb{P}(\Omega) = 1\)</span></p></li>
<li><p><strong>Aditividad numerable:</strong> si tienes una <strong>colecci√≥n infinita de eventos</strong> <span class="math notranslate nohighlight">\((A_1, A_2, A_3, \ldots)\)</span> que son <strong>mutuamente excluyentes</strong> (es decir, no se superponen, o sea, <span class="math notranslate nohighlight">\((A_i \cap A_j = \emptyset)\)</span> si <span class="math notranslate nohighlight">\(( i \ne j )\)</span>), entonces la probabilidad de que ocurra alguno de esos eventos (la uni√≥n de todos ellos) es igual a la <strong>suma de las probabilidades individuales</strong>.</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left( \bigcup_{i=1}^{\infty} A_i \right) = \sum_{i=1}^{\infty} \mathbb{P}(A_i)
\]</div>
<p>Esto garantiza que la probabilidad se comporta de manera coherente incluso cuando se trata de <strong>infinitas situaciones posibles</strong>, no solo finitas. Es una caracter√≠stica esencial para que una funci√≥n se considere una <strong>medida de probabilidad</strong> en <em>teor√≠a de la medida</em>.</p>
</div>
<blockquote>
<div><p>üìå <em>Nota:</em> Estos tres principios consolidan la probabilidad como una rama formal de la matem√°tica, basada en la <em>teor√≠a de conjuntos</em> y la <em>teor√≠a de la medida</em>.</p>
</div></blockquote>
<div class="tip admonition">
<p class="admonition-title">Evento en teor√≠a de probabilidad</p>
<p>En teor√≠a de probabilidad, un <strong>evento</strong> es cualquier subconjunto del espacio muestral <span class="math notranslate nohighlight">\(\Omega\)</span> que <strong>pertenece a la œÉ-√°lgebra</strong> <span class="math notranslate nohighlight">\((S)\)</span>.
Solo a estos eventos se les puede asignar una probabilidad formalmente v√°lida.
Por eso tambi√©n se les llama <strong>eventos medibles</strong>.</p>
</div>
<section id="como-se-relacionan-los-conceptos-que-hemos-visto">
<h5>¬øC√≥mo se relacionan los conceptos que hemos visto?<a class="headerlink" href="#como-se-relacionan-los-conceptos-que-hemos-visto" title="Link to this heading">#</a></h5>
<p>Para construir un modelo probabil√≠stico s√≥lido, necesitamos entender c√≥mo se relacionan tres objetos fundamentales: el <strong>espacio muestral</strong>, el <strong>conjunto potencia</strong> y la <strong>œÉ-√°lgebra</strong>.</p>
<ul class="simple">
<li><p>El <strong>espacio muestral</strong> <span class="math notranslate nohighlight">\(\Omega\)</span> es el punto de partida: contiene todos los posibles resultados de un experimento.</p></li>
<li><p>A partir de √©l, podemos formar el <strong>conjunto potencia</strong> <span class="math notranslate nohighlight">\(\mathcal{P}(\Omega)\)</span>, que incluye <strong>todos los subconjuntos posibles</strong> de <span class="math notranslate nohighlight">\(\Omega\)</span>. En principio, cada uno de estos subconjuntos podr√≠a considerarse un evento.</p></li>
<li><p>Sin embargo, no todos los subconjuntos de <span class="math notranslate nohighlight">\(\Omega\)</span> pueden ser tratados como <strong>eventos v√°lidos</strong> desde el punto de vista de la probabilidad. Para que un subconjunto sea un <strong>evento medible</strong>, debe pertenecer a una <strong>œÉ-√°lgebra</strong> <span class="math notranslate nohighlight">\(S \subseteq \mathcal{P}(\Omega)\)</span>, la cual cumple ciertas propiedades de consistencia l√≥gica (como estar cerrada bajo uni√≥n, complemento, etc.).</p></li>
</ul>
<p>Podemos resumir estas diferencias clave en la siguiente tabla:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Concepto</p></th>
<th class="head"><p>Qu√© representa</p></th>
<th class="head"><p>Contenido</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Espacio muestral <span class="math notranslate nohighlight">\((\Omega)\)</span></p></td>
<td><p>Resultados posibles de un experimento</p></td>
<td><p>Un conjunto base (como <span class="math notranslate nohighlight">\(\{1,2,3\})\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Conjunto potencia <span class="math notranslate nohighlight">\(\mathcal{P}(\Omega)\)</span></p></td>
<td><p>Todos los subconjuntos posibles de <span class="math notranslate nohighlight">\((\Omega)\)</span></p></td>
<td><p>Todos los eventos posibles, medibles o no</p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\sigma\)</span>-√°lgebra <span class="math notranslate nohighlight">\((S)\)</span></p></td>
<td><p>Subconjuntos <strong>medibles</strong> de <span class="math notranslate nohighlight">\((\Omega)\)</span></p></td>
<td><p>Subconjuntos que cumplen ciertas propiedades</p></td>
</tr>
</tbody>
</table>
</div>
<hr class="docutils" />
<p>La siguiente <strong>Figura 2</strong> ilustra visualmente c√≥mo se relacionan estos tres niveles de generalidad:</p>
<p><img alt="" src="../_images/all.jpg" /></p>
<p><strong>Figura 2.</strong> Relaci√≥n entre espacio muestral, conjunto potencia y <span class="math notranslate nohighlight">\(\sigma\)</span>-√°lgebra. Elaboraci√≥n propia.</p>
</section>
</section>
<section id="distribucion-de-probabilidad">
<h4>1.2.5. Distribuci√≥n de probabilidad<a class="headerlink" href="#distribucion-de-probabilidad" title="Link to this heading">#</a></h4>
<p>Una vez definida la funci√≥n de probabilidad <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>, podemos describir <strong>c√≥mo se reparte esa probabilidad</strong> entre los posibles resultados de un experimento. A esto lo llamamos <strong>distribuci√≥n de probabilidad</strong>.</p>
<p>Dependiendo del tipo de espacio muestral, la distribuci√≥n puede tomar dos formas principales:</p>
<hr class="docutils" />
<section id="distribuciones-discretas">
<h5>1.2.5.1 Distribuciones discretas<a class="headerlink" href="#distribuciones-discretas" title="Link to this heading">#</a></h5>
<p><img alt="" src="../_images/discrete-distr.png" /></p>
<p>Este tipo de distribuci√≥n se utiliza cuando el <em>espacio muestral</em> <span class="math notranslate nohighlight">\(\Omega\)</span> es <strong>finito o numerable</strong> (como lanzar un dado o una moneda).</p>
<p>Asignan una probabilidad expl√≠cita a cada valor individual de la variable aleatoria:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(X = x_i) = p_i \quad \text{con } \sum_i p_i = 1
\]</div>
<div class="tip admonition">
<p class="admonition-title">Ejemplo</p>
<p>Supongamos que lanzamos un dado justo.
Entonces <span class="math notranslate nohighlight">\(\Omega = \{1, 2, 3, 4, 5, 6\}\)</span> y usamos <span class="math notranslate nohighlight">\(\mathcal{P}(\Omega)\)</span> como <span class="math notranslate nohighlight">\(\sigma\)</span>-√°lgebra.</p>
<p>Definimos la probabilidad como:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(\{i\}) = \frac{1}{6} \quad \text{para } i = 1,\dots,6
\]</div>
<p>As√≠, por ejemplo:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbb{P}(\{2,4,6\}) = \frac{3}{6} = 0.5\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{P}(\{1\}) = \frac{1}{6}\)</span></p></li>
</ul>
</div>
</section>
<hr class="docutils" />
<section id="distribuciones-continuas">
<h5>1.2.5.1 Distribuciones continuas<a class="headerlink" href="#distribuciones-continuas" title="Link to this heading">#</a></h5>
<p><img alt="" src="../_images/cont-distr.png" /></p>
<p>Se definen sobre espacios infinitos (por ejemplo, <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>).
No asignan probabilidad a valores individuales, sino a intervalos, mediante una funci√≥n de densidad <span class="math notranslate nohighlight">\(f(x)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(a \leq X \leq b) = \int_a^b f(x)\, dx
\]</div>
<div class="tip admonition">
<p class="admonition-title">Ejemplo</p>
<p>La distribuci√≥n normal (o gaussiana) tiene densidad:</p>
<div class="math notranslate nohighlight">
\[
f(x) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2}
\]</div>
<p>Y cumple:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(f(x) \geq 0\)</span> para todo <span class="math notranslate nohighlight">\(x\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\int_{-\infty}^{\infty} f(x) \, dx = 1\)</span></p></li>
</ul>
<p>üí° <em>Nota:</em> <span class="math notranslate nohighlight">\(f(x)\)</span> no representa una probabilidad directa, sino una <strong>densidad</strong>:
la probabilidad de que <span class="math notranslate nohighlight">\(X\)</span> tome un valor exacto (como <span class="math notranslate nohighlight">\(X = 0\)</span>) es <strong>0</strong>. Solo intervalos tienen probabilidad positiva.</p>
</div>
<div class="note admonition">
<p class="admonition-title">Nota</p>
<p>Las <em>distribuciones de probabilidad</em> resumen toda la informaci√≥n necesaria para calcular eventos como:
<span class="math notranslate nohighlight">\(\mathbb{P}(X \in A)\)</span>, para cualquier conjunto medible <span class="math notranslate nohighlight">\(A \in S\)</span>.</p>
<ul class="simple">
<li><p>En el caso <strong>continuo</strong>, esto se hace mediante <strong>integrales</strong> sobre funciones de densidad.</p></li>
<li><p>En el caso <strong>discreto</strong>, mediante <strong>sumas</strong> de probabilidades individuales.</p></li>
</ul>
</div>
<blockquote>
<div><p>üìå <em>Nota:</em> Puedes explorar gr√°ficamente las diferentes distribuciones en <a class="reference external" href="https://seeing-theory.brown.edu/probability-distributions/index.html#section1">este recurso.</a></p>
</div></blockquote>
</section>
</section>
<section id="interpretaciones-de-la-probabilidad">
<h4>1.2.6. Interpretaciones de la probabilidad<a class="headerlink" href="#interpretaciones-de-la-probabilidad" title="Link to this heading">#</a></h4>
<p>Ya sabemos qu√© es una <em>funci√≥n de probabilidad</em> y c√≥mo puede <em>distribuirse</em> sobre un espacio muestral. Es importante notar que, en este punto, la <em>probabilidad</em> es un objeto estrictamente matem√°tico, cuya definici√≥n est√° separada del proceso mediante el cual se asignan probabilidades a los eventos.</p>
<p>Pero surge una pregunta fundamental:</p>
<blockquote>
<div><p><strong>¬øC√≥mo se asignan o calculan esos valores de probabilidad en la pr√°ctica?</strong></p>
</div></blockquote>
<p>La respuesta depende de la <strong>interpretaci√≥n</strong> que adoptemos sobre qu√© representa una probabilidad en un contexto real.</p>
<p>A continuaci√≥n, exploramos dos de las interpretaciones m√°s influyentes y ampliamente utilizadas: la <strong>frecuentista</strong> y la <strong>bayesiana</strong>.</p>
<section id="enfoque-frecuentista-medir-por-repeticion">
<h5>Enfoque frecuentista: medir por repetici√≥n<a class="headerlink" href="#enfoque-frecuentista-medir-por-repeticion" title="Link to this heading">#</a></h5>
<blockquote>
<div><p>Si repetimos un experimento muchas veces, el cociente entre el n√∫mero de veces que ocurre un evento y el total de repeticiones se usa como una estimaci√≥n de su probabilidad. Este valor es lo que se conoce como la <em>frecuencia relativa</em>.</p>
</div></blockquote>
<p>Este valor se llama <em>frecuencia relativa</em> del evento:</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}(A) \approx \frac{\#A}{n}\]</div>
<p>A medida que el n√∫mero de experimentos crece, esta frecuencia relativa tiende (bajo ciertas condiciones) a estabilizarse en un valor fijo. Este valor es interpretado como la <strong>probabilidad</strong> del evento desde el punto de vista <em>frecuentista</em>.</p>
<div class="attention admonition">
<p class="admonition-title">Frecuencia relativa</p>
<p>La <strong>frecuencia relativa</strong> es el cociente entre el n√∫mero de veces que ocurre un evento y el n√∫mero total de repeticiones del experimento. En el enfoque <strong>frecuentista</strong>, esta proporci√≥n se interpreta como la probabilidad del evento, especialmente cuando el n√∫mero de repeticiones es grande.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Ejemplo</p>
<p><img alt="" src="../_images/sesion2-freq.png" /></p>
<p>Si lanzamos una moneda 1000 veces y cae cara en 502 de ellas, entonces:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(\text{cara}) \approx \frac{502}{1000} = 0.502
\]</div>
<p>Al aumentar el n√∫mero de repeticiones, esta estimaci√≥n se estabiliza. Podemos observar este fen√≥meno en la <strong>Figura 3.</strong></p>
</div>
<p><img alt="Convergencia de la frecuencia relativa" src="../_images/frecuencia_relativa_frecuentista.png" /></p>
<p><strong>Figura 3</strong>. En el enfoque frecuentista, la probabilidad se interpreta como el valor al que tiende la <em>frecuencia relativa</em> de un evento (por ejemplo, ¬´cara¬ª en una moneda) conforme se incrementa el n√∫mero de repeticiones del experimento.</p>
<div class="caution admonition">
<p class="admonition-title">¬øEs s√≥lo una f√≥rmula?</p>
<p>Aunque el enfoque frecuentista utiliza la <em>frecuencia relativa</em> para estimar la probabilidad, <strong>no se reduce solamente a una f√≥rmula</strong>.</p>
<p>Este enfoque implica una forma espec√≠fica de entender qu√© es una probabilidad:</p>
<ol class="arabic simple">
<li><p>La probabilidad de un evento se <strong>define</strong> como el <strong>l√≠mite</strong> de su <em>frecuencia relativa</em> al repetir el experimento muchas veces.</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\lim_{n \to \infty} \frac{\#A}{n} = \mathbb{P}(A)\]</div>
<ol class="arabic simple" start="2">
<li><p>Se asume que las probabilidades son <strong>propiedades objetivas del mundo</strong>, no creencias subjetivas.</p></li>
<li><p>No se habla de probabilidades en eventos √∫nicos o no repetibles, como ‚Äúla probabilidad de que llueva ma√±ana‚Äù.</p></li>
</ol>
<p>Por tanto, el frecuentismo es una postura <strong>matem√°tica y filos√≥fica</strong>, no solo un m√©todo de c√°lculo.</p>
</div>
<blockquote>
<div><p><strong>¬øQu√© significa ¬´variable aleatoria¬ª en estad√≠stica frecuentista?</strong></p>
</div></blockquote>
<p>Hasta ahora, posiblemente has visto que una <em>variable aleatoria</em> es algo que usamos para modelar resultados inciertos, como lanzar un dado, medir una altura, o contar cu√°ntas veces sale cara una moneda.</p>
<p>Y eso es, precisamente, lo que significa en el enfoque <strong>frecuentista</strong>.</p>
<blockquote>
<div><p>Una <em>variable aleatoria</em> representa el <strong>resultado num√©rico</strong> de un experimento aleatorio que se puede repetir muchas veces.</p>
</div></blockquote>
<p>Por ejemplo, si lanzas una moneda y defines <span class="math notranslate nohighlight">\((X = 1)\)</span> si sale cara y <span class="math notranslate nohighlight">\((X = 0)\)</span> si sale cruz, entonces <span class="math notranslate nohighlight">\((X)\)</span> es una <em>variable aleatoria</em>.</p>
<p>Aqu√≠, lo aleatorio es el <strong>resultado</strong> del experimento, <strong>no</strong> el par√°metro que describe su comportamiento (como la probabilidad de que salga cara).</p>
<p>Desde esta perspectiva, <em>los par√°metros son constantes fijas, pero desconocidas</em> y no se modelan con variables aleatorias.</p>
<div class="note admonition">
<p class="admonition-title">Fundamento te√≥rico</p>
<p>El hecho de que la frecuencia relativa se estabilice a medida que aumenta el n√∫mero de repeticiones est√° respaldado por un resultado matem√°tico conocido como la <a class="reference external" href="https://es.wikipedia.org/wiki/Ley_de_los_grandes_n%C3%BAmeros"><strong>ley de los grandes n√∫meros</strong></a>.</p>
</div>
</section>
<section id="enfoque-bayesiano-probabilidades-como-creencias">
<h5>Enfoque bayesiano: probabilidades como creencias<a class="headerlink" href="#enfoque-bayesiano-probabilidades-como-creencias" title="Link to this heading">#</a></h5>
<p><em>¬øQu√© significa decir que algo tiene cierta probabilidad de ocurrir desde la perspectiva bayesiana?</em></p>
<p>El enfoque bayesiano propone una forma muy intuitiva de verlo:</p>
<blockquote>
<div><p>La probabilidad es una medida de qu√© tanto creemos que algo es cierto, bas√°ndonos en lo que sabemos hasta ahora.</p>
</div></blockquote>
<p>As√≠, para los bayesianos, la probabilidad no es una propiedad fija del mundo como ‚Äúla gravedad‚Äù, sino m√°s bien una forma de representar nuestra incertidumbre. Y lo m√°s importante:</p>
<blockquote>
<div><p>üí° Esa creencia puede cambiar si recibimos nueva informaci√≥n.</p>
</div></blockquote>
<div class="admonition-ejemplo admonition">
<p class="admonition-title">Ejemplo</p>
<p>Sup√≥n que alguien te dice:</p>
<blockquote>
<div><p><em>¬´Hay probabilidad de lluvia ma√±ana¬ª.</em></p>
</div></blockquote>
<p>Esa probabilidad puede ser diferente dependiento de si:</p>
<ul class="simple">
<li><p>viste un pron√≥stico confiable,</p></li>
<li><p>el cielo est√° completamente despejado,</p></li>
<li><p>o escuchaste truenos a lo lejos.</p></li>
</ul>
<p>Cada nueva pista <em>cambia tu creencia</em>. Y esto es justamente lo que el enfoque bayesiano busca formalizar: <strong>c√≥mo actualizamos</strong> nuestras creencias cuando obtenemos nueva evidencia.</p>
</div>
<blockquote>
<div><p>¬øC√≥mo se hace esto?</p>
</div></blockquote>
<p>La herramienta central para actualizar nuestras creencias es la <strong>probabilidad condicional</strong>:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(A \mid B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}
\]</div>
<p>Esta f√≥rmula expresa la probabilidad de que ocurra un evento <span class="math notranslate nohighlight">\((A)\)</span>, dado que se ha observado otro evento <span class="math notranslate nohighlight">\((B)\)</span>. La <strong>probabilidad condicional</strong> es el primer paso hacia un modelo bayesiano completo, ya que introduce la noci√≥n de <strong>informaci√≥n que modifica creencias</strong>.</p>
<div class="tip admonition">
<p class="admonition-title">Probabilidad condicional</p>
<p>La probabilidad condicional nos dice cu√°l es la probabilidad de que ocurra un evento <span class="math notranslate nohighlight">\((A)\)</span>, dado que ya sabemos que ha ocurrido otro evento <span class="math notranslate nohighlight">\((B)\)</span>.</p>
<p><img alt="" src="../_images/sesion2-probcondi.png" /></p>
<p>Por ejemplo, la probabilidad de lluvia puede cambiar si sabemos que el cielo est√° despejado. Esta forma de actualizar creencias es esencial en el enfoque <strong>bayesiano</strong>.</p>
</div>
<p>Aqu√≠ es donde entra en escena el famoso <strong>Teorema de Bayes</strong>.</p>
<div class="important admonition">
<p class="admonition-title">Teorema de Bayes: actualizaci√≥n de creencias</p>
<p>El Teorema de Bayes permite <strong>actualizar una creencia previa</strong> cuando se incorpora nueva informaci√≥n. Se compone de tres elementos:</p>
<ul class="simple">
<li><p><strong>Prior</strong>: lo que cre√≠amos antes de observar datos <span class="math notranslate nohighlight">\((P(A))\)</span></p></li>
<li><p><strong>Likelihood</strong> (verosimilitud): qu√© tan probable es observar los datos si la hip√≥tesis fuera cierta <span class="math notranslate nohighlight">\((P(B \mid A))\)</span></p></li>
<li><p><strong>Posterior</strong>: lo que creemos <strong>despu√©s</strong> de observar los datos <span class="math notranslate nohighlight">\((P(A \mid B))\)</span></p></li>
</ul>
<p><img alt="" src="../_images/sesion2-probcondi2.png" /></p>
<p>Este resultado es matem√°ticamente demostrable, y es la base de toda la estad√≠stica bayesiana.</p>
</div>
<blockquote>
<div><p><strong>¬øQu√© significa ¬´variable aleatoria¬ª en estad√≠stica bayesiana??</strong></p>
</div></blockquote>
<p>Hasta ahora, posiblemente has visto que una variable aleatoria es algo que usamos para modelar resultados inciertos, como lanzar un dado, medir una altura, o contar cu√°ntas veces sale cara una moneda.</p>
<p>Pero en el mundo bayesiano, las cosas se vuelven m√°s interesantes:</p>
<blockquote>
<div><p>Tambi√©n usamos variables aleatorias para representar lo que no sabemos sobre un par√°metro.</p>
</div></blockquote>
<p>Por ejemplo, imagina que est√°s tratando de averiguar cu√°l es la probabilidad <span class="math notranslate nohighlight">\(\theta\)</span> de que una m√°quina falle en un d√≠a cualquiera.
No tienes un n√∫mero exacto, pero‚Ä¶</p>
<blockquote>
<div><p><em>Creo que la m√°quina es bastante confiable, as√≠ que probablemente <span class="math notranslate nohighlight">\(\theta\)</span> sea algo as√≠ como 0.1‚Ä¶ pero no estoy segura¬ª</em></p>
</div></blockquote>
<p>Aqu√≠ no est√°s hablando de un resultado aleatorio, como el lanzamiento de un dado. Est√°s hablando de tu <strong>incertidumbre sobre un valor desconocido.</strong></p>
<p>Y eso, en bayes, se modela con una <em>variable aleatoria.</em></p>
<blockquote>
<div><p><strong>¬øY c√≥mo describimos esa incertidumbre?</strong></p>
</div></blockquote>
<p>Usamos lo que se llama una <strong>distribuci√≥n de probabilidad</strong>, que nos dice qu√© tan probable o cre√≠ble creemos que es cada posible valor de <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>Por ejemplo:</p>
<ul class="simple">
<li><p>Si pensamos que valores peque√±os de <span class="math notranslate nohighlight">\(\theta\)</span> (como 0.05 o 0.1) son m√°s probables, la distribuci√≥n ser√° m√°s alta en esa zona.</p></li>
<li><p>Si valores como 0.8 o 0.9 nos parecen muy poco probables, la distribuci√≥n ser√° muy baja all√≠.</p></li>
</ul>
<p>Esto se representa con una funci√≥n como:</p>
<div class="math notranslate nohighlight">
\[
p_X(x)
\]</div>
<p>significa que:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\((X)\)</span>: es la variable aleatoria que representa la probabilidad de un evento (como que salga cara).</p></li>
<li><p><span class="math notranslate nohighlight">\((x)\)</span>: es un valor posible de esa probabilidad (por ejemplo, 0.7).</p></li>
<li><p><span class="math notranslate nohighlight">\((p_X(x))\)</span>: es cu√°n cre√≠ble o probable consideramos ese valor, dada la informaci√≥n disponible.</p></li>
</ul>
<p><img alt="" src="../_images/sesion2-bayes_prob_de_probabilidad.png" /></p>
<p><strong>Figura 4.</strong> Notaci√≥n de la funci√≥n de densidad de probabilidad: <span class="math notranslate nohighlight">\(p_X(x)\)</span> represeta cu√°n probable o cre√≠ble creemos que es cada posible valor del par√°metro X.</p>
<p>En lugar de afirmar ‚Äúla probabilidad es 0.7‚Äù, el bayesiano dice: ‚Äú0.7 es plausible, pero tambi√©n lo son otros valores cercanos y esta es la distribuci√≥n que los describe‚Äù.</p>
<p><img alt="" src="../_images/bayes_prior_posterior.png" /></p>
<p><strong>Figura 5.</strong> En el enfoque bayesiano, una creencia inicial (distribuci√≥n prior, l√≠nea azul) se combina con la evidencia aportada por los datos (verosimilitud, l√≠nea roja) para producir una creencia actualizada (posterior, l√≠nea verde). Esto se realiza aplicando el Teorema de Bayes.</p>
<div class="tip admonition">
<p class="admonition-title">Resumen</p>
<p>En estad√≠stica bayesiana:</p>
<ul class="simple">
<li><p>Los par√°metros desconocidos se tratan como variables aleatorias.</p></li>
<li><p>Modelamos nuestras creencias sobre esos valores con distribuciones de probabilidad.</p></li>
<li><p>Cuando obtenemos nuevos datos, actualizamos esas creencias usando el Teorema de Bayes.</p></li>
</ul>
</div>
<iframe width="650" height="315"
    src="https://www.youtube.com/embed/XIbL0foEckA"
    title="YouTube video player"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen>
</iframe>
<hr class="docutils" />
<p><img alt="" src="../_images/interpretations-joke.png" /></p>
<hr class="docutils" />
<p>Una vez que entendemos qu√© representa una probabilidad y c√≥mo se puede interpretar, el siguiente paso natural es analizar <strong>c√≥mo se combinan o se relacionan distintos eventos entre s√≠</strong>.</p>
<p>Esto nos lleva a estudiar conceptos fundamentales como la <strong>probabilidad condicional, conjunta y marginal</strong>.</p>
</section>
</section>
<section id="probabilidad-conjunta-condicional-y-marginal">
<h4>1.2.7. Probabilidad conjunta, condicional y marginal<a class="headerlink" href="#probabilidad-conjunta-condicional-y-marginal" title="Link to this heading">#</a></h4>
<p>Hasta ahora hemos aprendido a:</p>
<ul class="simple">
<li><p>Definir un <strong>espacio muestral</strong> <span class="math notranslate nohighlight">\((\Omega)\)</span>, que contiene todos los posibles resultados de un experimento.</p></li>
<li><p>Considerar subconjuntos de <span class="math notranslate nohighlight">\((\Omega)\)</span> como <strong>eventos</strong>, organizados en una estructura llamada <span class="math notranslate nohighlight">\((\sigma)\)</span>-√°lgebra.</p></li>
<li><p>Asignar valores de <strong>probabilidad</strong> a esos eventos mediante funciones que cumplen ciertos principios (como los axiomas de Kolmog√≥rov).</p></li>
<li><p>Interpretar esos valores bajo los enfoques <strong>frecuentista</strong> y <strong>bayesiano</strong>.</p></li>
</ul>
<p>Este marco nos permite describir eventos <strong>individuales</strong>, pero tambi√©n <strong>eventos compuestos</strong>: por ejemplo, cuando dos condiciones ocurren a la vez, o una depende de otra.</p>
<hr class="docutils" />
<section id="que-nos-permite-considerar-eventos-compuestos">
<h5>¬øQu√© nos permite considerar eventos compuestos?<a class="headerlink" href="#que-nos-permite-considerar-eventos-compuestos" title="Link to this heading">#</a></h5>
<p>La clave est√° en la <span class="math notranslate nohighlight">\((\sigma)\)</span>-√°lgebra:</p>
<blockquote>
<div><p>Al definir el espacio de eventos como una <span class="math notranslate nohighlight">\((\sigma)\)</span>-√°lgebra, garantizamos que podemos operar con ellos de forma l√≥gica y estructurada:</p>
<ul class="simple">
<li><p>unir eventos <span class="math notranslate nohighlight">\((A \cup B)\)</span></p></li>
<li><p>tomar complementos <span class="math notranslate nohighlight">\((A^c)\)</span></p></li>
<li><p>y tambi√©n <strong>intersecciones</strong> como <span class="math notranslate nohighlight">\((A \cap B)\)</span>, que representan <strong>eventos conjuntos</strong>.</p></li>
</ul>
</div></blockquote>
<p>Esto no solo nos permite construir descripciones m√°s ricas de situaciones, sino que nos habilita a hacer <strong>operaciones de probabilidad</strong> sobre m√∫ltiples eventos.</p>
<p>A continuaci√≥n, exploraremos tres operaciones fundamentales:</p>
</section>
<hr class="docutils" />
<section id="probabilidad-conjunta">
<h5>1. Probabilidad conjunta<a class="headerlink" href="#probabilidad-conjunta" title="Link to this heading">#</a></h5>
<p>La <strong>probabilidad conjunta</strong> mide la probabilidad de que <strong>dos eventos ocurran al mismo tiempo</strong>.</p>
<p>Se denota como:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(A \cap B)
\]</div>
<p>o, si el contexto lo permite, simplemente <span class="math notranslate nohighlight">\(\mathbb{P}(A, B)\)</span>.</p>
<div class="tip admonition">
<p class="admonition-title">Ejemplo</p>
<p>Si <span class="math notranslate nohighlight">\((A = \{\text{llover}\})\)</span> y <span class="math notranslate nohighlight">\((B = \{\text{llevar paraguas}\})\)</span>,
entonces <span class="math notranslate nohighlight">\((\mathbb{P}(A \cap B))\)</span> representa la probabilidad de que <strong>llueva y lleves paraguas</strong> el mismo d√≠a.</p>
</div>
</section>
<section id="probabilidad-condicional">
<h5>2. Probabilidad condicional<a class="headerlink" href="#probabilidad-condicional" title="Link to this heading">#</a></h5>
<p>La <strong>probabilidad condicional</strong> responde a la pregunta:</p>
<blockquote>
<div><p>¬øCu√°l es la probabilidad de que ocurra (A) si ya sabemos que ocurri√≥ (B)?</p>
</div></blockquote>
<p>Se define como:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(A \mid B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)} \quad \text{si } \mathbb{P}(B) &gt; 0
\]</div>
<div class="tip admonition">
<p class="admonition-title">Ejemplo</p>
<p>Si <span class="math notranslate nohighlight">\((\mathbb{P}(\text{llover y llevar paraguas}) = 0.3 )\)</span>
y <span class="math notranslate nohighlight">\((\mathbb{P}(\text{llevar paraguas}) = 0.5)\)</span>,
entonces:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(\text{llover} \mid \text{llevar paraguas}) = \frac{0.3}{0.5} = 0.6
\]</div>
</div>
</section>
<section id="probabilidad-marginal">
<h5>3. Probabilidad marginal<a class="headerlink" href="#probabilidad-marginal" title="Link to this heading">#</a></h5>
<p>La <strong>probabilidad marginal</strong> es la probabilidad de un evento <strong>sin condicionar</strong> en ning√∫n otro.</p>
<p>Cuando trabajamos con variables m√∫ltiples, podemos obtener la marginal de una variable ‚Äúresumiendo‚Äù la informaci√≥n sobre las otras.</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(A) = \sum_{b} \mathbb{P}(A, B=b)
\]</div>
<p>En el caso continuo:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(A) = \int \mathbb{P}(A, B)\, dB
\]</div>
<div class="note admonition">
<p class="admonition-title">Nota</p>
<p>La marginal es √∫til cuando queremos concentrarnos en un solo evento o variable, ignorando otras que tambi√©n est√°n en juego.</p>
</div>
</section>
</section>
<section id="reglas-derivadas-de-la-probabilidad">
<h4>1.2.8. Reglas derivadas de la probabilidad<a class="headerlink" href="#reglas-derivadas-de-la-probabilidad" title="Link to this heading">#</a></h4>
<p>Una vez que hemos definido formalmente la <strong>probabilidad condicional</strong>, podemos deducir tres reglas fundamentales que se utilizan constantemente en modelado probabil√≠stico.</p>
<p>Estas reglas no son nuevos axiomas, sino <strong>consecuencias directas</strong> de combinar:</p>
<ul class="simple">
<li><p>Los <strong>axiomas de Kolmog√≥rov</strong>, especialmente:</p>
<ul>
<li><p>La aditividad: <span class="math notranslate nohighlight">\(P(A \cup B) = P(A) + P(B)\)</span> si <span class="math notranslate nohighlight">\(A \cap B = \varnothing\)</span></p></li>
</ul>
</li>
<li><p>La <strong>definici√≥n de probabilidad condicional</strong></p></li>
</ul>
<p>Veamos cada una:</p>
<section id="regla-de-marginalizacion">
<h5>üìå Regla de marginalizaci√≥n<a class="headerlink" href="#regla-de-marginalizacion" title="Link to this heading">#</a></h5>
<p>Se basa en la <strong>aditividad</strong>: si <span class="math notranslate nohighlight">\(B\)</span> puede tomar varios valores disjuntos, entonces:</p>
<div class="math notranslate nohighlight">
\[
P(A) = \sum_B P(A, B)
\]</div>
<p>Esta regla permite <strong>reducir</strong> una probabilidad conjunta a una <strong>marginal</strong>.</p>
</section>
<hr class="docutils" />
<section id="regla-de-la-cadena">
<h5>üìå Regla de la cadena<a class="headerlink" href="#regla-de-la-cadena" title="Link to this heading">#</a></h5>
<p>Viene directamente de <em>reordenar</em> la definici√≥n de probabilidad condicional:</p>
<div class="math notranslate nohighlight">
\[
P(A \mid B) = \frac{P(A, B)}{P(B)} \quad \Rightarrow \quad P(A, B) = P(A \mid B) \cdot P(B)
\]</div>
<p>Esta relaci√≥n es fundamental en estructuras secuenciales como los modelos gr√°ficos.</p>
<p>Tambi√©n puede escribirse sim√©tricamente:</p>
<div class="math notranslate nohighlight">
\[
P(B, A) = P(B \mid A) \cdot P(A)
\]</div>
</section>
<hr class="docutils" />
<section id="regla-de-la-probabilidad-total">
<h5>üìå Regla de la probabilidad total<a class="headerlink" href="#regla-de-la-probabilidad-total" title="Link to this heading">#</a></h5>
<p>Surge al aplicar <strong>marginalizaci√≥n</strong> sobre la <strong>regla de la cadena</strong>:</p>
<div class="math notranslate nohighlight">
\[
P(A) = \sum_B P(A, B) = \sum_B P(A \mid B) \cdot P(B)
\]</div>
<p>Es decir, descomponemos la probabilidad de <span class="math notranslate nohighlight">\(A\)</span> en funci√≥n de sus componentes condicionales respecto a <span class="math notranslate nohighlight">\(B\)</span>.</p>
<div class="tip admonition">
<p class="admonition-title">Nota t√©cnica</p>
<p>En el contexto de probabilidad, usamos la notaci√≥n <span class="math notranslate nohighlight">\(P(A, B)\)</span> como abreviatura de <span class="math notranslate nohighlight">\(P(A \cap B)\)</span> (la probabilidad de que ocurran ambos eventos).</p>
</div>
<blockquote>
<div><p>Adem√°s de ser √∫til para calcular probabilidades marginales,<br />
la <strong>regla de la probabilidad total</strong> tambi√©n puede interpretarse como una <strong>constante de normalizaci√≥n</strong>:</p>
<p>garantiza que la distribuci√≥n condicional resultante ( P(A \mid B) ) sea <strong>v√°lida</strong>,<br />
es decir, que <strong>sume 1</strong> al considerar todos los posibles valores de (A).</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[\sum_A P(A \mid B) = 1\]</div>
<p><img alt="" src="../_images/reglas_probabilidad_diagrama.png" /></p>
<p><strong>Figura 5.</strong> La definici√≥n de probabilidad condicional permite derivar tres reglas fundamentales: la <strong>regla de la cadena</strong>, la <strong>regla de marginalizaci√≥n</strong> y la <strong>regla de la probabilidad total</strong>. Estas relaciones son la base del razonamiento probabil√≠stico en contextos donde intervienen m√∫ltiples eventos.</p>
</section>
</section>
<section id="independencia">
<h4>1.2.9. Independencia<a class="headerlink" href="#independencia" title="Link to this heading">#</a></h4>
<p>Uno de los conceptos m√°s importantes en teor√≠a de probabilidad es el de <strong>independencia entre eventos o variables</strong>. Intuitivamente, dos eventos son independientes si el conocimiento de uno <strong>no cambia</strong> la probabilidad del otro.</p>
<blockquote>
<div><p>La independencia <strong>no se asume</strong> ni se deduce por intuici√≥n: <strong>se verifica formalmente</strong>.</p>
</div></blockquote>
<div class="tip admonition">
<p class="admonition-title">Definici√≥n formal</p>
<p>Dos eventos <span class="math notranslate nohighlight">\(A\)</span> y <span class="math notranslate nohighlight">\(B\)</span> son independientes si:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(A \mid B) = \mathbb{P}(A)
\quad \text{o equivalentemente} \quad
\mathbb{P}(A \cap B) = \mathbb{P}(A) \cdot \mathbb{P}(B)
\]</div>
<p>Esta √∫ltima igualdad es m√°s com√∫nmente usada, ya que no requiere el c√°lculo de probabilidades condicionales (evita divisiones por cero cuando <span class="math notranslate nohighlight">\(\mathbb{P}(B) = 0\)</span>).</p>
</div>
<section id="simetria">
<h5>Simetr√≠a<a class="headerlink" href="#simetria" title="Link to this heading">#</a></h5>
<p>Una propiedad importante de la independencia es que <strong>es sim√©trica</strong>:</p>
<p>Si <span class="math notranslate nohighlight">\(A\)</span> es independiente de <span class="math notranslate nohighlight">\(B\)</span>, entonces <span class="math notranslate nohighlight">\(B\)</span> es independiente de <span class="math notranslate nohighlight">\(A\)</span>.</p>
</section>
<section id="alternativa-para-variables">
<h5>Alternativa para variables<a class="headerlink" href="#alternativa-para-variables" title="Link to this heading">#</a></h5>
<p>Dos variables aleatorias <span class="math notranslate nohighlight">\(X\)</span> y <span class="math notranslate nohighlight">\(Y\)</span> son independientes si:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(X = x, Y = y) = \mathbb{P}(X = x) \cdot \mathbb{P}(Y = y)
\quad \text{para todo } x, y
\]</div>
<blockquote>
<div><p>üìå <em>Nota:</em> basta con que una sola combinaci√≥n no cumpla la igualdad para que las variables no sean independientes.</p>
</div></blockquote>
<div class="tip admonition">
<p class="admonition-title">Ejemplo</p>
<p>Sup√≥n que lanzamos dos monedas. Sea <span class="math notranslate nohighlight">\(\alpha\)</span>: <em>‚Äúla primera moneda resulta en cara‚Äù</em>, y <span class="math notranslate nohighlight">\(\beta\)</span>: <em>‚Äúla segunda moneda resulta en cara‚Äù</em>. Estos eventos son independientes: saber que uno ocurri√≥ no afecta la probabilidad del otro.</p>
<p>Tambi√©n en procesos m√°s abstractos, la independencia puede surgir de la estructura del experimento. Por ejemplo:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span>: <em>¬´el resultado del dado es par¬ª</em></p></li>
<li><p><span class="math notranslate nohighlight">\(\beta\)</span>: <em>¬´el resultado es 1 o 2¬ª</em></p></li>
</ul>
<p>Si el dado es justo, es f√°cil verificar que:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(\alpha \cap \beta) = \mathbb{P}(\alpha) \cdot \mathbb{P}(\beta) = \frac{1}{2} \cdot \frac{1}{3} = \frac{1}{6}
\]</div>
<p>Por lo tanto, <span class="math notranslate nohighlight">\(\alpha\)</span> y <span class="math notranslate nohighlight">\(\beta\)</span> son eventos independientes.</p>
</div>
</section>
</section>
<section id="independencia-condicional">
<h4>1.2.10. Independencia condicional<a class="headerlink" href="#independencia-condicional" title="Link to this heading">#</a></h4>
<p>La <strong>independencia</strong> es una propiedad √∫til, pero poco com√∫n en problemas reales:<br />
en la pr√°ctica, es raro que dos variables o eventos sean verdaderamente independientes.</p>
<p>Sin embargo, lo que s√≠ ocurre con frecuencia es que <strong>dos variables sean independientes <em>condicionalmente</em></strong> a una tercera.<br />
Es decir:</p>
<blockquote>
<div><p><strong>Dado que sabemos algo</strong>, esa informaci√≥n ‚Äúexplica‚Äù o ‚Äúdesvincula‚Äù a las otras dos variables.</p>
</div></blockquote>
<div class="tip admonition">
<p class="admonition-title">Definici√≥n formal</p>
<p>Decimos que <span class="math notranslate nohighlight">\(A\)</span> y <span class="math notranslate nohighlight">\(B\)</span> son <strong>condicionalmente independientes dado <span class="math notranslate nohighlight">\(X\)</span></strong>, si se cumple:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(A, B \mid X) = \mathbb{P}(A \mid X) \cdot \mathbb{P}(B \mid X)
\]</div>
<p>Lo cual tambi√©n implica que:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(A \mid B, X) = \mathbb{P}(A \mid X)
\quad \text{y} \quad
\mathbb{P}(B \mid A, X) = \mathbb{P}(B \mid X)
\]</div>
</div>
<blockquote>
<div><p>üìå <em>Nota:</em> La informaci√≥n de <span class="math notranslate nohighlight">\(X\)</span> ‚Äúbloquea‚Äù la dependencia entre <span class="math notranslate nohighlight">\(A\)</span> y <span class="math notranslate nohighlight">\(B\)</span>.<br />
Es decir, <strong>una vez que sabemos <span class="math notranslate nohighlight">\(X\)</span></strong>, las otras dos variables &gt; <strong>no se influyen entre s√≠</strong>.</p>
</div></blockquote>
<div class="tip admonition">
<p class="admonition-title">Ejemplo</p>
<p>Sup√≥n que queremos estimar la probabilidad de que una estudiante sea admitida a un posgrado en el ITAM o en el CINVESTAV.</p>
<ul class="simple">
<li><p>Sea <span class="math notranslate nohighlight">\(I\)</span>: <em>¬´fue admitida al posgrado del ITAM¬ª</em></p></li>
<li><p>Sea <span class="math notranslate nohighlight">\(C\)</span>: <em>¬´fue admitida al posgrado del CINVESTAV¬ª</em></p></li>
</ul>
<p>Normalmente, <span class="math notranslate nohighlight">\(I\)</span> y <span class="math notranslate nohighlight">\(C\)</span> <strong>no son independientes</strong>: saber que fue admitida al ITAM probablemente aumenta nuestra creencia de que tambi√©n ser√° admitida al CINVESTAV, porque sugiere que es una estudiante sobresaliente.</p>
<p>Ahora supongamos que sabemos que su promedio de licenciatura (<span class="math notranslate nohighlight">\(G\)</span>) es de 9.5, y que ambas instituciones <strong>basan su admisi√≥n √∫nicamente en el promedio</strong>.</p>
<p>Entonces, <strong>dado <span class="math notranslate nohighlight">\(G = 9.5\)</span></strong>, los eventos <span class="math notranslate nohighlight">\(I\)</span> y <span class="math notranslate nohighlight">\(C\)</span> s√≠ son independientes:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(C \mid I, G) = \mathbb{P}(C \mid G)
\]</div>
<p>En este caso, decimos que <strong><span class="math notranslate nohighlight">\(C\)</span> es condicionalmente independiente de <span class="math notranslate nohighlight">\(I\)</span> dado <span class="math notranslate nohighlight">\(G\)</span></strong>.</p>
</div>
<div class="admonition-tip admonition">
<p class="admonition-title">Tip</p>
<p>Diremos que <span class="math notranslate nohighlight">\(A \perp B \mid C\)</span> si se cumple:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(A \cap B \mid C) = \mathbb{P}(A \mid C) \cdot \mathbb{P}(B \mid C)
\]</div>
</div>
<div class="admonition-notacion-comun admonition">
<p class="admonition-title">Notaci√≥n com√∫n</p>
<p><span class="math notranslate nohighlight">\(A \perp B \mid C\)</span>:
A es independiente de B dado C.</p>
<p>Tambi√©n se puede escribir:
<span class="math notranslate nohighlight">\(\mathbb{P}(A \mid B, C) = \mathbb{P}(A \mid C)\)</span></p>
</div>
</section>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="M1-sesion1.html"
       title="p√°gina anterior">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">anterior</p>
        <p class="prev-next-title">Sesi√≥n 1</p>
      </div>
    </a>
    <a class="right-next"
       href="M1-sesion3.html"
       title="siguiente p√°gina">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">siguiente</p>
        <p class="prev-next-title">Sesi√≥n 3</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contenido
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#repaso-de-probabilidad">1. Repaso de probabilidad</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#introduccion">1.1. Introducci√≥n</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fundamentos-de-la-teoria-de-probabilidad">1.2. Fundamentos de la teor√≠a de probabilidad</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#espacio-muestral-omega">1.2.1. Espacio muestral <span class="math notranslate nohighlight">\((\Omega)\)</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conjunto-potencia-mathcal-p-omega">1.2.2. Conjunto potencia <span class="math notranslate nohighlight">\(\mathcal{P}(\Omega)\)</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#algebra-s-o-espacio-de-eventos">1.2.3. œÉ-√°lgebra <span class="math notranslate nohighlight">\((S)\)</span> o espacio de eventos</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#funcion-de-probabilidad">1.2.4. Funci√≥n de probabilidad</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#como-se-relacionan-los-conceptos-que-hemos-visto">¬øC√≥mo se relacionan los conceptos que hemos visto?</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#distribucion-de-probabilidad">1.2.5. Distribuci√≥n de probabilidad</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuciones-discretas">1.2.5.1 Distribuciones discretas</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#distribuciones-continuas">1.2.5.1 Distribuciones continuas</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretaciones-de-la-probabilidad">1.2.6. Interpretaciones de la probabilidad</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#enfoque-frecuentista-medir-por-repeticion">Enfoque frecuentista: medir por repetici√≥n</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#enfoque-bayesiano-probabilidades-como-creencias">Enfoque bayesiano: probabilidades como creencias</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilidad-conjunta-condicional-y-marginal">1.2.7. Probabilidad conjunta, condicional y marginal</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#que-nos-permite-considerar-eventos-compuestos">¬øQu√© nos permite considerar eventos compuestos?</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilidad-conjunta">1. Probabilidad conjunta</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilidad-condicional">2. Probabilidad condicional</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilidad-marginal">3. Probabilidad marginal</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#reglas-derivadas-de-la-probabilidad">1.2.8. Reglas derivadas de la probabilidad</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#regla-de-marginalizacion">üìå Regla de marginalizaci√≥n</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#regla-de-la-cadena">üìå Regla de la cadena</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#regla-de-la-probabilidad-total">üìå Regla de la probabilidad total</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#independencia">1.2.9. Independencia</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#simetria">Simetr√≠a</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#alternativa-para-variables">Alternativa para variables</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#independencia-condicional">1.2.10. Independencia condicional</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Por MCD. Paty Munoz
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2025, Paty Munoz.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>