{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599ccc30",
   "metadata": {},
   "source": [
    "# Sesi√≥n 1\n",
    "\n",
    "## Motivaci√≥n\n",
    "\n",
    "El curso de Modelos Gr√°ficos Probabil√≠sticos ofrece una formaci√≥n rigurosa en herramientas fundamentales para la representaci√≥n y el an√°lisis de sistemas complejos bajo incertidumbre. A trav√©s de una combinaci√≥n de teor√≠a de probabilidad, estad√≠stica y estructuras gr√°ficas, permite modelar dependencias entre variables.\n",
    "\n",
    "Este curso est√° orientado a quienes deseen profundizar en t√©cnicas clave del aprendizaje autom√°tico y su aplicaci√≥n en campos como la inteligencia artificial, la bioinform√°tica, la visi√≥n computacional y el procesamiento de lenguaje natural."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e994781",
   "metadata": {},
   "source": [
    "### Ejercicio de motivaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c297365",
   "metadata": {
    "tags": [
     "Thebe"
    ]
   },
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_iris\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f020b2d3",
   "metadata": {},
   "source": [
    "Disponible en: [Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff3c75a",
   "metadata": {},
   "source": [
    "#### Machine Learning, everywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15809674",
   "metadata": {},
   "source": [
    "![](../images/memes/eee1.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e931ca1c",
   "metadata": {},
   "source": [
    "Sabemos que una de las ramas m√°s relevantes de la inteligencia artificial es el _Machine Learning_. Esta disciplina, a trav√©s de diversos modelos y algoritmos, tiene como objetivo principal generar predicciones a partir de _datos_. \n",
    "\n",
    "En este contexto, analizaremos el cl√°sico conjunto de datos `iris`. A partir de sus caracter√≠sticas ‚Äîcomo la _longitud_ y la _altura_ de los s√©palos‚Äî construiremos un modelo de clasificaci√≥n que nos permita _predecir_ a qu√© especie pertenece cada flor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3ea773",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd86dc19",
   "metadata": {},
   "source": [
    "| **Property**        | **Value**       |\n",
    "|---------------------|-----------------|\n",
    "| Classes             | 3               |\n",
    "| Samples per class   | 50              |\n",
    "| Samples total       | 150             |\n",
    "| Dimensionality      | 4               |\n",
    "| Features            | real, positive  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1afb580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf7aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un DataFrame con los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b684dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2613ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# np.random.seed(1)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 6)) \n",
    "\n",
    "# # Dispersi√≥n con ruido para evitar superposici√≥n\n",
    "# sc = ax.scatter(\n",
    "#     df.length + np.random.normal(loc=0, scale=0.1, size=len(df)),\n",
    "#     df.width + np.random.normal(loc=0, scale=0.1, size=len(df)),\n",
    "#     c=df.target,\n",
    "#     cmap='cividis',\n",
    "#     alpha=0.6,\n",
    "#     edgecolors='w',\n",
    "#     linewidths=0.5,\n",
    "#     s=60\n",
    "# )\n",
    "\n",
    "\n",
    "# ax.set_xlabel(\"Sepal length (cm)\", fontsize=12)\n",
    "# ax.set_ylabel(\"Sepal width (cm)\", fontsize=12)\n",
    "# ax.set_title(\"Clasificaci√≥n por longitud y ancho del s√©palo\", fontsize=14, pad=15)\n",
    "\n",
    "# ax.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# cbar = fig.colorbar(sc, ax=ax)\n",
    "# cbar.set_label('Clase', fontsize=11)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c0a1b",
   "metadata": {},
   "source": [
    "| Tipo de flor | N√∫mero |\n",
    "| ------------ | ------ |\n",
    "| Setosa       | 0      |\n",
    "| Versicolor   | 1      |\n",
    "| Virginica    | 2      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d149c7f9",
   "metadata": {},
   "source": [
    "#### ¬øqu√© observamos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2648777e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary> üßø </summary>\n",
    "  \n",
    "  * Clase 0 (color morado oscuro) est√° bien separada: se agrupa con s√©palos m√°s cortos y m√°s anchos.\n",
    "\n",
    "  * Clase 1 y Clase 2 (verde y amarillo) est√°n m√°s superpuestas, especialmente en la regi√≥n de s√©palos largos y estrechos.\n",
    "\n",
    "  * Esto sugiere que, al menos con las variables ``sepal length`` y ``sepal width``, la clase 0 se puede clasificar con mayor precisi√≥n que las otras dos.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94d386",
   "metadata": {},
   "source": [
    "**Pregunta:**\n",
    "\n",
    "_¬øCu√°les modelos de clasificaci√≥n podr√≠amos usar para resolver este problema?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ed986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificador de √°rbol de decisi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53090fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b14d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8394df99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bef2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bafc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# promedio anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5637fe",
   "metadata": {},
   "source": [
    "#### ¬øPor qu√© usar una distribuci√≥n conjunta para clasificar?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfcf5cc",
   "metadata": {},
   "source": [
    "Anteriormente vimos que un modelo de clasificaci√≥n (como √°rboles de decisi√≥n) presenta un _score_ del 60%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc931e87",
   "metadata": {},
   "source": [
    "Podemos adoptar un **enfoque probabil√≠stico** para modelar la situaci√≥n a partir de los datos disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1026a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180da34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8a18df",
   "metadata": {},
   "source": [
    "Primero, ve√°mos en la tabla siguiente que las columnas (`L`, `W` `T`) representan todas las posibles combinaciones de valores de cada variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d19e8",
   "metadata": {},
   "source": [
    "La tabla muestra la **distribuci√≥n conjunta** de tres variables (`L`, `W`, `T`).\n",
    "\n",
    "Al estimar la distribuci√≥n conjunta de las variables $(L)$ (longitud del tallo), $(W)$ (ancho del tallo) y $(T)$ (tipo de flor), obtenemos un modelo probabil√≠stico completo:\n",
    "\n",
    "$$P(L, W, T)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f93a22f",
   "metadata": {},
   "source": [
    "Este enfoque tiene varias ventajas:\n",
    "\n",
    "- Captura todas las relaciones entre las variables.\n",
    "- Nos permite derivar distribuciones condicionales √∫tiles para clasificaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff69264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_train.groupby(['L', 'W', 'T']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80ace80",
   "metadata": {},
   "source": [
    "Tenemos $4 * 3 * 3 = 36$ posibles combinaciones:\n",
    "\n",
    "**NOTA:** no todas las combinaciones posibles de (`L`, `W` `T`) aparecen en los datos. `groupby().size()` solo muestra las combinaciones que realmente est√°n presentes en el DataFrame.\n",
    "\n",
    "Las combinaciones que no ocurren ni una sola vez, no aparecen en la salida porque su conteo es $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58274c8a",
   "metadata": {},
   "source": [
    "| L | W | T | Frecuencia |\n",
    "|---|---|---|------------|\n",
    "| 4 | 2 | 0 | 2          |\n",
    "| 4 | 2 | 1 | 1          |\n",
    "| 4 | 2 | 2 | 1          |\n",
    "| 4 | 3 | 0 | 16         |\n",
    "| 5 | 2 | 1 | 17         |\n",
    "| 5 | 2 | 2 | 5          |\n",
    "| 5 | 3 | 0 | 22         |\n",
    "| 5 | 3 | 1 | 6          |\n",
    "| 5 | 3 | 2 | 1          |\n",
    "| 6 | 2 | 1 | 10         |\n",
    "| 6 | 2 | 2 | 11         |\n",
    "| 6 | 3 | 1 | 9          |\n",
    "| 6 | 3 | 2 | 18         |\n",
    "| 7 | 2 | 2 | 3          |\n",
    "| 7 | 3 | 1 | 1          |\n",
    "| 7 | 3 | 2 | 8          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb16f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empirical joint distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef962e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.isclose(empirical_joint_distr.sum(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75bec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empirical_joint_distr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e85f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defbd2d5",
   "metadata": {},
   "source": [
    "Por ejemplo, a partir de la distribuci√≥n conjunta podemos obtener la probabilidad de que una flor pertenezca a cierta clase $(T)$, dado que observamos un par de medidas $((L, W))$:\n",
    "\n",
    "$$\n",
    "P(T \\mid L, W) = \\frac{P(L, W, T)}{P(L, W)}\n",
    "$$\n",
    "\n",
    "Con esta informaci√≥n, podemos construir un clasificador probabil√≠stico de la siguiente manera:\n",
    "\n",
    "1. La distribuci√≥n condicional nos proporciona una probabilidad para cada posible valor $(t)$ que puede tomar la variable $(T)$ (por ejemplo, $(t = 0, 1, 2 )$). Como nuestro objetivo es predecir la clase m√°s probable, elegimos el valor de $(t)$ que maximiza esta probabilidad:\n",
    "\n",
    "$$\n",
    "\\hat{t} = \\arg\\max_{t} P(T = t \\mid L = \\ell, W = w)\n",
    "$$\n",
    "\n",
    "2. Este procedimiento se conoce como el **clasificador MAP (Maximum A Posteriori)**. Es importante destacar que no necesitamos calcular expl√≠citamente la distribuci√≥n condicional, ya que:\n",
    "\n",
    "$$\n",
    "P(T = t \\mid L = \\ell, W = w) = \\frac{P(T = t, L = \\ell, W = w)}{P(L = \\ell, W = w)}\n",
    "$$\n",
    "\n",
    "3. Dado que el denominador $(P(L = \\ell, W = w))$ no depende de $(t)$, podemos omitirlo durante la maximizaci√≥n. Esto nos permite simplificar el clasificador a:\n",
    "\n",
    "$$\n",
    "\\hat{t} = \\arg\\max_{t} P(T = t, L = \\ell, W = w)\n",
    "$$\n",
    "\n",
    "Este enfoque nos permite realizar clasificaci√≥n directamente a partir de la distribuci√≥n conjunta estimada, sin necesidad de modelos adicionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e049d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empirical_joint_distr[7, 3].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e330b930",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{t} = \\arg\\max_{t} \\, \\hat{P}(T = t, L = 5, W = 3)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0cb12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8df2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# promedio de aciertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7445485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d61125",
   "metadata": {},
   "source": [
    "### üìå Conclusi√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00193b7",
   "metadata": {},
   "source": [
    "**¬øLo que hice corresponde a un modelo generativo?**\n",
    "\n",
    "S√≠, el procedimiento que implementaste es completamente coherente con el enfoque de un **modelo generativo**. \n",
    "\n",
    "**Pasos que seguiste (en t√©rminos probabil√≠sticos)**\n",
    "\n",
    "1. **Estimaci√≥n de la distribuci√≥n conjunta**\n",
    "\n",
    "   Calculaste la probabilidad conjunta $(P(L = \\ell, W = w, T = t))$ a partir de los datos, contando la frecuencia de cada combinaci√≥n y normalizando sobre el total.  \n",
    "   ‚Üí Esto es exactamente lo que har√≠a un modelo generativo: aprender la **distribuci√≥n conjunta** $(P(X, Y))$.\n",
    "\n",
    "2. **Normalizaci√≥n**\n",
    "\n",
    "   Dividiste los conteos conjuntos por el total de observaciones, obteniendo as√≠ una estimaci√≥n emp√≠rica de las probabilidades.  \n",
    "   ‚Üí Esto convierte los conteos en una **distribuci√≥n de probabilidad v√°lida**.\n",
    "\n",
    "3. **C√°lculo de la probabilidad condicional**\n",
    "\n",
    "   Usaste la regla de Bayes para obtener la distribuci√≥n condicional:\n",
    "\n",
    "   $$\n",
    "   P(T = t \\mid L = \\ell, W = w) = \\frac{P(L = \\ell, W = w, T = t)}{P(L = \\ell, W = w)}\n",
    "   $$\n",
    "\n",
    "   ‚Üí Esto es una inferencia cl√°sica dentro del enfoque generativo.\n",
    "\n",
    "4. **Predicci√≥n con argumento m√°ximo (MAP)**\n",
    "\n",
    "   Elegiste la clase con mayor probabilidad condicional:\n",
    "\n",
    "   $$\n",
    "   \\hat{t} = \\arg\\max_t P(T = t \\mid L = \\ell, W = w)\n",
    "   $$\n",
    "\n",
    "   ‚Üí Esto implementa el **clasificador MAP (Maximum A Posteriori)**.\n",
    "\n",
    "5. **Clasificaci√≥n final**\n",
    "\n",
    "   Aplicaste este procedimiento a cada punto del conjunto de datos, generando predicciones basadas √∫nicamente en la distribuci√≥n conjunta estimada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37f397e",
   "metadata": {},
   "source": [
    "**OJO**\n",
    "\n",
    "Que ambos modelos obtengan el mismo _score_ no significa que sean equivalentes, sino que **dado el conjunto de datos y la tarea, ambos llegaron al l√≠mite razonable de desempe√±o**.\n",
    "\n",
    "Ambos tienen ventajas:\n",
    "- El modelo probabil√≠stico aporta una visi√≥n basada en evidencia y probabilidades.\n",
    "- El √°rbol de decisi√≥n proporciona reglas claras y visualmente interpretables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e66534",
   "metadata": {},
   "source": [
    "[_Cr√©ditos del ejercicio_](https://github.com/esjimenezro/mgp2025/tree/main/m1-intro-modelado-probabilistico/c1-motivacion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
