# Sesi√≥n 3

## 1. Repaso de probabilidad

### 1.1. Variables aleatorias discretas

```{admonition} Definici√≥n
:class: note

Sea $\Omega$ un espacio muestral discreto, es decir, un conjunto finito o numerable de posibles resultados de un experimento aleatorio.

Una variable aleatoria discreta es una funci√≥n que asigna un n√∫mero real a cada elemento de $\Omega$:

$$
X: \Omega \to \mathbb{R}
$$

Es decir, toma un resultado del experimento aleatorio y lo traduce a un n√∫mero real que nos interesa analizar o interpretar.
```

#### 1.1.1. ¬øpor qu√© usamos variables aleatorias?

Cuando trabajamos con variables aleatorias, no nos enfocamos directamente en los resultados del experimento (como obtener un 3 y un 5 al lanzar dos datos), sino en _alguna cantidad derivada_ de esos resultados: una suma, una ganacia, un conteo, etc.

Esto nos permite:

- Modelar situaciones de forma num√©rica.
- Usar herramientas matem√°ticas para analizar fen√≥menos aleatorios.
- Calcular cantidades como la probabilidad de √©xito, el valor esperado o la variabilidad de un resultado.

##### Ejemplo

Supongamos que lanzamos dos dados. El espacio mestral es:

$$
\Omega = \{(i,j): i,j=1, 2, \dots, 6\}.
$$

Este conjunto tiene 36 posibles pares ordenados, y si los dados son justos, cada uno tiene la misma probabilidad:

$$p(i, j) = \frac{1}{36}$$

Ahora, supongamos el siguiente juego:

- Ganas $500 si la suma de los datos es 7.
- Pierdes $100 en cualquier otro caso.

Podemos **definir una variable aleatoria discreta $X(i, j)$** que represente la ganacia del juego:

$$
X(i,j) = \left\lbrace
\begin{array}{lc}
500  &  \text{si } i+j=7 \\
-100 &  \text{si } i+j\neq7
\end{array}
\right .
$$

```{admonition} Interpretaci√≥n
:class: tip

Esta **variable aleatoria** convierte los resultados del experimento (el lanzamiento de los dados) en una cantidad que nos interesa: la ganancia o p√©rdida en el juego.

As√≠, en lugar de analizar directamente los pares $(i, j)$, analizamos el _comportamiento_ de $X$, que ya resume lo que queremos estudiar.
```

#### 1.1.2. Funci√≥n de masa de probabilidad (PMF)

Una vez que tenemos una variable aleatoria discreta $X$, queremos saber con qu√© probabilidad toma cada uno de sus posibles valores.

Para eso usamos la funci√≥n de masa de probabilidad o PMF _(Probability Mass Function)_.

##### ¬øqu√© hace la PMF?

La PMF asigna una probabilidad a cada valor posible que puede tomar la variable aleatoria.

En otras palabras:

> La PMF mapea cada valor real que puede tomar $X$ al n√∫mero entre 0 y 1 que representa su **probabilidad**.

Formalmente, si $x$ es un valor posible de la variable aleatoria $X$, entonces:

$$
P(X=x) = \text{probabilidad de que } X \text{ tome el valor } x.
$$

Esto define la funci√≥n de masa de probabilidad:

$$
f_X(x) = P(X=x)
$$

#### 1.1.3 Funci√≥n de distribuci√≥n acumulada (CDF)

La funci√≥n de distribuci√≥n acumulada ‚Äîconocida como CDF _(Cumulative Distribution Function)_‚Äî es una forma alternativa de describir una variable aleatoria discreta $X$.

##### ¬øqu√© hace la CDF?

La CDF asigna a cada valor $x$ la probabilidad de que la variable aleatoria $X$ tome un valor **menor o igual** a $x$.

Formalmente, la CDF se define como:

$$
F_X(x) = P(X \leq x) = \sum_{x_i \leq x} P(X = x_i)
$$

```{admonition} Propiedades de la CDF
:class: note

- $F(x)$ es **mon√≥tona no decreciente**: nunca baja.

- $0 \leq F(x) \leq 1$.

- $\lim_{x \to \infty} F(x) = 1$.

- $\lim_{x \to -\infty} F(x) = 0$.
```

Como tabla, siguiendo el ejemplo de los dados:

$$
F(a) = p(X \leq x).
$$

| x      | 1   | 2   | 3   | 4   | 5   | 6   |
| ------ | --- | --- | --- | --- | --- | --- |
| p(X=x) | 0.3 | 0   | 0   | 0   | 0.3 | 0.4 |
| F(x)   | 0.3 | 0.3 | 0.3 | 0.3 | 0.6 | 1   |

```{admonition} OJO
:class: warning

Es f√°cil notar que:

- $(0 \leq p(a) \leq 1)$
- $(x)$ puede ser cualquier n√∫mero. Si $(x)$ es un valor que $(X)$ nunca toma, entonces $(p(x) = 0)$.

üî∏ La **primera afirmaci√≥n aplica tanto para la PMF como para la CDF**:
Ambas funciones siempre devuelven valores entre 0 y 1.

üî∏ La **segunda afirmaci√≥n aplica solo para la PMF**:
La CDF $(F(x) = \mathbb{P}(X \leq x))$ puede ser mayor que 0 incluso si $(X)$ nunca toma el valor exacto $(x)$, porque **acumula** las probabilidades de los valores menores o iguales a $(x)$.
```

Recapitulando, tenemos:

| **Concepto**            | **Palabra clave**           | **¬øQu√© representa?**                              |
| ----------------------- | --------------------------- | ------------------------------------------------- |
| Espacio muestral        | ‚ÄúTodo lo posible y medible‚Äù | Todas las salidas del experimento                 |
| Funci√≥n de probabilidad | ‚ÄúPeso‚Äù                      | Cu√°n probable es cada resultado                   |
| Variable aleatoria      | ‚ÄúTraducci√≥n‚Äù                | Asocia un n√∫mero a cada resultado del experimento |
| Distribuci√≥n            | ‚ÄúComportamiento‚Äù            | C√≥mo se reparten los valores que genera $(X)$     |

### 1.2. Distribuciones de probabilidad discretas

#### 1.2.1. Distribuci√≥n de Bernoulli

**Qu√© modela:**

Un solo experimento con dos posibles resultados: √©xito (1) o fracaso (0).

**Ejemplo:**

Tirar una moneda una vez:

- Cara = 1 (√©xito)
- Cruz = 0 (fracaso)

**Par√°metros:**
$\theta \in [0, 1]$ es la probabilidad de √©xito.

Se denota como:

$$
X \sim \text{Bernoulli}(\theta)
$$

#### 1.2.2. Distribuci√≥n Binomial

**Qu√© modela:**
El n√∫mero total de √©xitos en $n$ experimentos independientes de Bernoulli.

**Ejemplo:**
Tirar una moneda $n$ veces y contar cu√°ntas veces sale cara.

**Par√°metros:**

- $n$: n√∫mero de ensayos
- $\theta$: probabilidad de √©xito en cada ensayo

Se denota como:

$$
X \sim \text{Binomial}(n, \theta)
$$

#### 1.2.3 Distribuci√≥n Geom√©trica

**Qu√© modela:**
El n√∫mero de ensayos hasta obtener el primer √©xito (incluyendo ese √©xito).

**Ejemplo:**
Tirar una moneda hasta que salga cara por primera vez.
Si sale cara en el tercer intento, $X=3$.

**Par√°metros:**
$\theta$: probabilidad de √©xito en cada intento.

Se denota como:

$$
X \sim \text{Geometric}(\theta)
$$

```{admonition} Nota
:class: note

Ahora que hemos visto ejemplos importantes de distribuciones discretas como la _Bernoulli, Binomial y Geom√©trica_, podemos estudiar una de las propiedades fundamentales de una variable aleatoria: su valor esperado, tambi√©n conocido como **esperanza matem√°tica**.

La esperanza nos da una idea del "promedio" que esperar√≠amos obtener si repiti√©ramos el experimento muchas veces. Es una medida central que resume el comportamiento de la distribuci√≥n.
```

### 1.3 Esperanza y varianza (discretas)

#### 1.3.1 Esperanza

Antes de definirla formalmente, es importante notar que el valor esperado no solo se aplica a la variable aleatoria en s√≠, sino tambi√©n a **cualquier funci√≥n de la variable**. Es decir, podemos calcular el valor esperado de $f(X)$, donde $(f)$ es una funci√≥n que transforma los valores de la variable aleatoria.

Esto permite, por ejemplo, obtener cantidades como:

- la varianza: $\mathbb{E}[X^2]$
- la utilidad esperada: $\mathbb{E}[\log X]$
- el valor esperado de p√©rdidas u otras m√©tricas de inter√©s

Este enfoque m√°s general se expresa como:

$$
\mathbb{E}[f(X)] = \sum_x p(x) \cdot f(x)
$$

Y si tomamos $f(x) = x$, recuperamos la forma m√°s com√∫n del valor esperado:

$$
\mathbb{E}[X] = \sum_x p(x) \cdot x
$$

#### 1.3.2 Varianza

El valor esperado es una _medida de tendencia central_, en el sentido de que nos da un valor promedio, o ‚Äúcentro de gravedad‚Äù probabil√≠stico, hacia el cual tienden los datos al repetirse el experimento muchas veces.

Sin embargo, **no nos dice qu√© tan dispersos est√°n los valores alrededor de ese promedio**. Para eso, necesitamos una medida de variabilidad: la **varianza**.

La varianza de una funci√≥n $f(X)$, denotada como $\mathrm{var}_p[f]$, se define como:

$$
\mathrm{var}_p[f] = \mathbb{E}_p\left[(f(x) - \mathbb{E}_p[f])^2\right]
$$

Esta expresi√≥n se interpreta como el **promedio ponderado de los cuadrados de las desviaciones** entre los valores de $f(x)$ y su esperanza. En otras palabras: mide **cu√°nto var√≠an los valores alrededor de su media**.

Una forma algebraicamente m√°s sencilla y muy √∫til para calcular la varianza es:

$$
\mathrm{var}_p[f] = \mathbb{E}_p[f(x)^2] - \left(\mathbb{E}_p[f]\right)^2
$$

Esta f√≥rmula permite calcular la varianza a partir de **dos esperanzas**:

- La esperanza del cuadrado de $f(x)$
- El cuadrado de la esperanza de $f(x)$

#### 1.3.3 C√°lculo de esperanza y varianza de variable aleatoria Bernoulli

Sea $X$ una variable aleatoria que toma valores en el conjunto $\{0, 1\}$. Se denota como:

![Distribuci√≥n Bernoulli](../images/bernulli-1.png)

- En **verde**, se resalta la probabilidad $P(X = 1) = \theta$.
- En **azul**, se muestra que $P(X = 0) = 1 - \theta$.

## Esperanza de una variable Bernoulli

La esperanza matem√°tica o valor esperado de $X$ se define como:

![Esperanza de X](../images/bernulli-2.png)

- Los t√©rminos en **azul** y **verde** ayudan a identificar qu√© probabilidad corresponde a cada valor posible de $X$.
- El resultado final, $\mathbb{E}[X] = \theta$, est√° **enmarcado en morado** para destacarlo.

---

## A) Esperanza de $X^2$

Dado que los √∫nicos valores posibles de $X$ son 0 y 1, se cumple que $X^2 = X$. Por lo tanto:

![Esperanza de X al cuadrado](../images/bernulli-3.png)

- Esta igualdad se debe a que $0^2 = 0$ y $1^2 = 1$, as√≠ que no hay cambio al elevar al cuadrado.

---

## B) Varianza de una variable Bernoulli

La varianza se calcula con la f√≥rmula:

![Varianza de X](../images/bernulli-4.png)

- Se utiliza el resultado anterior $\mathbb{E}[X] = \theta$.
- El desarrollo muestra c√≥mo se simplifica la f√≥rmula hasta obtener $\theta(1 - \theta)$, que aparece resaltado al final.

---

## Conclusi√≥n

Una variable aleatoria Bernoulli con par√°metro $\theta$ tiene:

- **Esperanza:** $\mathbb{E}[X] = \theta$
- **Varianza:** $\text{Var}(X) = \theta(1 - \theta)$

---

## 1.4. Variables aleatorias continuas

Las variables aleatorias continuas son aquellas que pueden tomar **infinitos valores dentro de un intervalo real**, como por ejemplo, el tiempo, la temperatura, o la altura de una persona. A diferencia de las variables discretas (que solo pueden asumir valores separados como 0, 1, 2...), las variables continuas pueden asumir **cualquier n√∫mero real dentro de un rango**.

### 1.4.0. Antes de empezar: ¬øqu√© es densidad? ¬øy qu√© es integrar?

```{admonition} Densidad e integraci√≥n
:class: note

_Densidad_ e _integraci√≥n_ son conceptos que surgen cuando tratamos de entender lo continuo. Ambos responden a una necesidad: **describir y cuantificar lo que no se puede contar.**

* Densidad: es una funci√≥n que representa la concentraci√≥n relatica de algo en un entorno continuo. No mide "cu√°nto hay", sino _qu√© tan distribuido est√°_ eso que queremos medir, por unidad de espacio, tiempo o dominio.

* Integraci√≥n: es el proceso mediante el cual se convierte una distribuci√≥n infinitesimal en una cantidad total. Si la densidad es el contenido local, integrar es el acto de extraer de ella un contenido global.

La integral es necesaria porque en lo continuo ninguna parte individual puede ser medida por s√≠ sola. Solo al acumular contribuciones infinitesimales podemos obtener algo cuantificable.

Densidad e integraci√≥n son conceptos **interdependientes**. La densidad _no tiene significado cuantitativo por s√≠ sola_; solo mediante la integraci√≥n puede usarse para calcular algo. A su vez, integrar _no tiene sentido si no hay una funci√≥n que describa lo que se est√° acumulando_.

```

### 1.4.1. Funci√≥n de densidad de probabilidad (PDF)

En las variables aleatorias continuas usamos una **funci√≥n de densidad de probabilidad**, tambi√©n llamada **PDF** (por sus siglas en ingl√©s: _Probability Density Function_). Esta funci√≥n, que denotamos como $f(x)$, **no representa una probabilidad**, sino una **densidad de probabilidad**.

Esto es parecido al concepto de densidad en f√≠sica: **no mide cu√°nta cantidad hay**, sino **cu√°nta cantidad hay por unidad**.

Entonces, para obtener la probabilidad de que una variable continua $X$ est√© dentro de un intervalo $[a, b]$, integramos la densidad en ese intervalo:

$$
P(a \leq X \leq b) = \int_a^b f(x)\, dx
$$

Aqu√≠, la integral cumple el rol que antes cumpl√≠a la suma en las distribuciones discretas.

#### Propiedades de una PDF

Para que una funci√≥n $f(x)$ sea una densidad de probabilidad v√°lida, debe cumplir dos condiciones:

1. **No negatividad**:

   $$
   f(x) \geq 0 \quad \text{para todo } x
   $$

2. **Normalizaci√≥n**:
   $$
   \int_{-\infty}^{\infty} f(x)\, dx = 1
   $$
   Esto garantiza que la probabilidad total (en todo el espacio) sea 1.

---

#### Conexi√≥n conceptual

- $f(x)$: representa **c√≥mo se distribuye la probabilidad** (pero no cu√°nto hay).
- $\int_a^b f(x)\, dx$: representa **cu√°nta probabilidad hay** en ese intervalo.
- Sin integraci√≥n, la densidad **no tiene contenido num√©rico**.
- Sin densidad, la integraci√≥n **no tiene objeto que acumular**.

### 1.4.2. Funci√≥n de distribuci√≥n acumulada (CDF)

La **funci√≥n de distribuci√≥n acumulada** (abreviada como **CDF**, del ingl√©s _Cumulative Distribution Function_) es una herramienta que nos permite conocer **la probabilidad acumulada hasta un punto dado**.

Dada una variable aleatoria continua $X$ con funci√≥n de densidad de probabilidad $f(x)$, la CDF se define como:

$$
F(x) = P(X \leq x) = \int_{-\infty}^x f(t)\, dt
$$

Esta integral representa **la cantidad total de probabilidad acumulada desde $-\infty$ hasta el punto $x$**.

Mientras que la PDF $f(x)$ nos dice **d√≥nde se concentra** la probabilidad, la CDF $F(x)$ nos dice **cu√°nta probabilidad se ha acumulado hasta cierto valor**.

Por ejemplo:

- $F(1)$ es la probabilidad de que $X$ tome un valor menor o igual a 1.
- $F(3) - F(1)$ es la probabilidad de que $X$ est√© entre 1 y 3.

#### Conexi√≥n conceptual

| Concepto          | PDF ($f(x)$)                               | CDF ($F(x)$)                        |
| ----------------- | ------------------------------------------ | ----------------------------------- |
| ¬øQu√© representa?  | Densidad local de probabilidad             | Probabilidad acumulada hasta $x$    |
| ¬øC√≥mo se obtiene? | Derivando la CDF                           | Integrando la PDF                   |
| ¬øPara qu√© sirve?  | Ver d√≥nde est√° concentrada la probabilidad | Calcular intervalos de probabilidad |

---

### Ejemplo de uso

Para calcular la probabilidad de que $X$ est√© entre $a$ y $b$:

$$
P(a \leq X \leq b) = F(b) - F(a)
$$

Esto es equivalente a integrar la densidad:

$$
\int_a^b f(x)\, dx = F(b) - F(a)
$$

---

La CDF nos permite responder preguntas probabil√≠sticas de forma directa y es especialmente √∫til cuando la integral de la PDF no tiene forma cerrada, pero la CDF s√≠.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

### 1.4.5. Distribuciones continuas

#### üìê Distribuci√≥n uniforme

Modela situaciones donde todos los valores en un intervalo $[a, b]$ son **igualmente probables**.

Par√°metros: $a$, $b$  
Soporte: $x \in [a, b]$  
Densidad:

$$
f(x) = \begin{cases}
\frac{1}{b - a}, & a \leq x \leq b \\
0, & \text{en otro caso}
\end{cases}
$$

#### ‚è≥ Distribuci√≥n exponencial

Modela **tiempos de espera entre eventos** que ocurren continuamente y de forma independiente.

Par√°metro: $\lambda$ (tasa)  
Soporte: $x \in [0, \infty)$  
Densidad:

$$
f(x) = \lambda e^{-\lambda x}
$$

#### üîî Distribuci√≥n normal

Modela fen√≥menos naturales con **concentraci√≥n alrededor de un valor central**.

Par√°metros: $\mu$ (media), $\sigma$ (desviaci√≥n est√°ndar)  
Soporte: $x \in (-\infty, \infty)$  
Densidad:

$$
f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( -\frac{(x - \mu)^2}{2\sigma^2} \right)
$$

Es la famosa **curva de campana**.
