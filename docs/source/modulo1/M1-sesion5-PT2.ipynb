{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a005fc3",
   "metadata": {},
   "source": [
    "# Sesión 5 B\n",
    "\n",
    "## La distribución previa como regularizador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9508a5f5",
   "metadata": {},
   "source": [
    "> **Objetivos:**\n",
    "> - Comprender el principio de estimación Máximum A-Posteriori (MAP).\n",
    "> - Entender el efecto de la distribución previa como regularizador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878bebf2",
   "metadata": {},
   "source": [
    "### I. Introducción\n",
    "\n",
    "En este cuaderno de trabajo exploraremos un enfoque _intermedio_ entre la perspectiva bayesiana y la frecuentista.\n",
    "\n",
    "#### Recordemos primero la visión frecuentista\n",
    "\n",
    "En el enfoque frecuentista aparece el concepto de **estimadores puntuales**. \n",
    "\n",
    "```{admonition} Estimadores puntuales\n",
    ":class: note\n",
    "\n",
    "Un estimador puntual es una función de los datos observados que proporciona una _única estimación_ del valor de un parámetro desconocido.\n",
    "```\n",
    "\n",
    "Desde esta perspectiva:\n",
    "\n",
    "* Tenemos una situación con incertidumbre.\n",
    "\n",
    "* Para describirla, planteamos un modelo parametrizado por un conjunto de parámetros desconocidos.\n",
    "\n",
    "* El objetivo es encontrar el valor de esos parámetros que mejor se ajuste a los datos disponibles.\n",
    "\n",
    "* En notación matemática, podríamos escribir el modelo como:\n",
    "\n",
    "$$\n",
    "M(\\theta) = p(\\theta|D)\n",
    "$$\n",
    "\n",
    "#### Ideas clave en la visión frecuentista\n",
    "\n",
    "* Los parámetros *existen* y son *valores fijos*, aunque no los conozcamos.\n",
    "\n",
    "* Lo que queremos es encontrar esos valores.\n",
    "\n",
    "* La incertidumbre *no está en los parámetros*, sino en los datos.\n",
    "\n",
    "Como consecuencia, aparece la función de verosimilitud: \n",
    "\n",
    "$$L(\\theta|D)$$\n",
    "\n",
    "que mide qué tan probable es observar los datos bajo diferentes valores de $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5fc4bc",
   "metadata": {},
   "source": [
    "#### La perspectiva bayesiana\n",
    "\n",
    "Veamos ahora el mismo problema desde la estadística bayesiana.\n",
    "\n",
    "Partimos de la mismo situación:\n",
    "\n",
    "* Tenemos incertidumbre\n",
    "\n",
    "* Contamos con un modelo parametrizado\n",
    "\n",
    "* Y disponemos de un conjunto de datos observados\n",
    "\n",
    "La diferencia clave está en cómo entendemos la _fuente de la incertidumbre:_\n",
    "\n",
    "* Para los frecuentistas, los datos son aleatorios y los parámetros son fijos (aunque desconocidos).\n",
    "\n",
    "* Para los bayesianos, sucede al revés:\n",
    "    * Los datos ya están fijos (no hay incertidumbre en ellos una vez observados).\n",
    "\n",
    "    * La incertidumbre está en los parámetros, porque no conocemos sus valores. \n",
    "\n",
    "```{admonition} En otras palabras\n",
    ":class: tip\n",
    "\n",
    "Como _bayesianos_ no nos preguntamos únicamente _\"¿cuál es el valor de $\\theta$ que mejor explica los datos?\"_, sino _\"¿cuál es la probabilidad de cada posible valor de $\\theta$, dado lo que ya observamos?\"_.\n",
    "\n",
    "Matemáticamente, expresamos esta idea con la **distribución posterior**:\n",
    "\n",
    "$$\n",
    "p(\\theta | D)\n",
    "$$\n",
    "\n",
    "donde $D$ son los datos (fijos) y $\\theta$ representa los parámetros (inciertos). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac66ef10",
   "metadata": {},
   "source": [
    "#### Un punto intermedio: el estimador MAP\n",
    "\n",
    "Hemos visto dos perspectivas:\n",
    "\n",
    "* Frecuentista: los parámetros son **valores fijos** (desconocidos) y la incertidumbre está en los **datos**.\n",
    "\n",
    "* Bayesiana: los parámetros tienen una **distribución de probabilidad** y la incertidumbre está en los **parámetros**, mientras que los datos observados son **valores fijos**.\n",
    "\n",
    "Entre estos dos enfoques surge una visión _intermedia_, que da lugar a otros tipo de estimador: el **estimador de máximo a posteriori (MAP)**.\n",
    "\n",
    "\n",
    "```{admonition} ¿qué significa el MAP?\n",
    ":class: note\n",
    "\n",
    "- Desde Bayes sabemos que la *distribución posterior* es proporcional a la *verosimilitud* multiplicada por la *distribución previa*:  \n",
    "\n",
    "$$\n",
    "p(\\theta \\mid D) \\propto L(\\theta \\mid D) \\, p(\\theta)\n",
    "$$\n",
    "\n",
    "- En lugar de trabajar con toda la distribución posterior (como en Bayes puro), buscamos *el valor de $\\theta$ que maximiza esta posterior*.  \n",
    "\n",
    "Es decir, definimos el estimador MAP como:  \n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_{MAP} = \\arg\\max_\\theta \\; \\big[ \\; L(\\theta \\mid D)\\, p(\\theta) \\;\\big]\n",
    "$$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a399d",
   "metadata": {},
   "source": [
    "#### Conexión con la regularización\n",
    "\n",
    "Aquí aparece algo muy interesante que veremos a continuación, pero antes introduzcamos la distribución normal multivariable, puesto que nos será útil para obtener la función de densidad de probabilidad normal multivariada:\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(x|\\mu, \\Sigma) = \\frac{1}{\\sqrt{\\det(2 \\pi \\Sigma)}} \\exp \\left\\{-\\frac{1}{2}(x - \\mu)^T \\Sigma^{-1} (x - \\mu)\\right\\},\n",
    "$$\n",
    "\n",
    "con parámetros $\\mu \\in \\mathbb{R}^d$: vector de medias de la V.A. $X$ y $\\Sigma \\in \\mathbb{R}^{d \\times d}$: matriz de covarianzas de la VA X (simétrica y definida positiva)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25d20988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "181bccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stats.multivariate_normal(\n",
    "    mean=[0, 0],\n",
    "    cov=[\n",
    "        [1, 0],\n",
    "        [0, 1]\n",
    "    ]\n",
    ")\n",
    "Y = stats.multivariate_normal(\n",
    "    mean=[1, 1],\n",
    "    cov=[\n",
    "        [1, -0.8],\n",
    "        [-0.8, 1]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea646522",
   "metadata": {},
   "source": [
    "```{admonition} Intuición\n",
    ":class: tip\n",
    "\n",
    "Una normal multivariada puede imaginarse como una campana en varias dimensiones.\n",
    "\n",
    "* La media marca el centro de la campana.\n",
    "\n",
    "* La covarianza define la forma:\n",
    "\n",
    "  * sin correlación → contornos circulares,\n",
    "\n",
    "  * con correlación → contornos elípticos e inclinados.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ee27b",
   "metadata": {},
   "source": [
    "![](../images/sesion5_multi1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccca78e",
   "metadata": {},
   "source": [
    "**Figura 1.** Distribución normal bivariada con media en $(0,0)$ y matriz de covarianza diagonal. Los contornos circulares reflejan independencia y dispersión igual en todas las direcciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce95ff3",
   "metadata": {},
   "source": [
    "![](../images/sesion5_multi2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc0e7bc",
   "metadata": {},
   "source": [
    "**Figura 2.** Distribución normal bivariada con media en $(1,1)$ y covarianza no diagonal. Los contornos elípticos inclinados muestran la correlación negativa entre las variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a465f515",
   "metadata": {},
   "source": [
    "```{admonition} Matriz de covarianzas\n",
    ":class: tip\n",
    "\n",
    "La matriz de covarianza describe cómo varían las variables entre sí:\n",
    "\n",
    "* Diagonal → varianzas de cada variable (qué tan dispersas están).\n",
    "\n",
    "* Fuera de la diagonal → covarianzas (si aumentan o disminuyen juntas).\n",
    "\n",
    "* Valores positivos → relación directa,\n",
    "\n",
    "* Valores negativos → relación inversa,\n",
    "\n",
    "* Ceros → independencia (sin relación lineal).\n",
    "\n",
    "En una normal multivariada, esta matriz es la que da forma y orientación a los contornos (círculos o elipses)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf8393",
   "metadata": {},
   "source": [
    "### II. Retomemos ajuste de curvas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca7636",
   "metadata": {},
   "source": [
    "Con lo anterior dicho, volvamos a hablar del tema de *ajuste de curvas* con una perspectiva probabilística. \n",
    "\n",
    "Partimos de nuevo modelando la relación entre nuestra variable de salida $y$ y las variables de entrada $x$ como un **modelo lineal** con incertidumbre, la cual suponemos normal:\n",
    "\n",
    "$$\n",
    "y = \\phi(x)^T w + \\epsilon,\n",
    "$$\n",
    "\n",
    "con $\\epsilon \\sim \\mathcal{N}(0, \\beta^{-1})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6597a95",
   "metadata": {},
   "source": [
    "Equivalentemente, podemos decir que:\n",
    "\n",
    "$$\n",
    "y \\sim \\mathcal{N}(\\phi(x)^T w, \\beta^{-1}),\n",
    "$$\n",
    "\n",
    "con esta suposición podemos determinar que la verosimilitud de un datos, sigue una distribución normal con:\n",
    "\n",
    "$$\n",
    "p(y | x, w) = \\mathcal{N}(y | \\phi(x)^T w, \\beta^{-1}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa753cd3",
   "metadata": {},
   "source": [
    "Ya sabemos a donde nos conduce este modelo para la función de verosimilitud. \n",
    "\n",
    "Alternativamente, encontremos una expresión para la distribución posterior de los parámetros, usando la regla de Bayes:\n",
    "\n",
    "\\begin{align}\n",
    "p(w | y, X) & = \\frac{p(y, w | X)}{p(y | X)} \\qquad \\text{(Definición de probabilidad condicional)} \\\\\n",
    "            & = \\frac{p(y | X, w) p(w | X)}{p(y | X)} \\qquad \\text{(Bayes)}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec984b8",
   "metadata": {},
   "source": [
    "En este contexto, tenemos que:\n",
    "\n",
    "- $p(w | y, X)$ es la distribución posterior de los parámetros dados los datos.\n",
    "\n",
    "- $p(y | X, w) = \\mathcal{L}(w) = \\prod_{i=1}^{N} \\mathcal{N}(y_i | \\phi(x_i)^T w, \\beta^{-1})$ es la función de verosimilitud.\n",
    "\n",
    "- $p(y | X)$ es la distribución de evidencia.\n",
    "\n",
    "- $p(w | X)$ es la distribución previa. Para este punto, una suposición que hace bastante sentido es que conocer únicamente las variables de entrada $X$ no nos dice absolutamente nada acerca de los parámetros $w$. Es decir, **son independientes**. Por tanto,\n",
    "\n",
    "  $$\n",
    "  p(w | X) = p(w).\n",
    "  $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2d2bbb",
   "metadata": {},
   "source": [
    "#### Maximizar la distribución posterior (MAP)\n",
    "\n",
    "Aquí convergen los dos mundos, es decir, razonamos acerca de la **distribución posterior** de los parámetros con Bayes, pero **tomaremos un valor puntual del parámetro más probable**. \n",
    "\n",
    "Maximizamos la distribución posterior:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{w}_{MAP} & = \\arg \\max_{w} p(w | y, X) \\\\\n",
    "              & = \\arg \\max_{w} \\frac{p(y | X, w) p(w | X)}{p(y | X)} \\\\\n",
    "              & = \\arg \\max_{w} p(y | X, w) p(w | X) \\qquad \\text{(La distribución de evidencia no depende de $w$)} \\\\\n",
    "              & = \\arg \\max_{w} \\log p(y | X, w) + \\log p(w) \\qquad \\text{(El logaritmo es una función creciente y cóncava)} \\\\\n",
    "              & = \\arg \\max_{w} l(w) + \\log p(w)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3b2ae4",
   "metadata": {},
   "source": [
    "El término de log-verosimilitud ya lo conocemos:\n",
    "\n",
    "$$\n",
    "l(w) = \\frac{N}{2}\\log\\beta - \\frac{N}{2}\\log(2 \\pi) - \\frac{\\beta}{2} \\left|\\left|y - \\Phi w\\right|\\right|^2,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624aa11a",
   "metadata": {},
   "source": [
    "La pregunta es, **¿Qué es la distribución previa $p(w)$?**\n",
    "\n",
    "- Este término nos permite expresar todo nuestro conocimiento previo acerca de los parámetros $w$ de una manera probabilística, es decir, a través de una distribución de probabilidad.\n",
    "\n",
    "#### Previa normal\n",
    "\n",
    "Una elección común es:\n",
    "  \n",
    "\\begin{align}\n",
    "p(w) & = \\mathcal{N}(w | 0, \\alpha^{-1} I) \\\\\n",
    "   & = \\frac{1}{\\sqrt{\\det(2 \\pi \\alpha^{-1} I)}} \\exp \\left\\{-\\frac{\\alpha}{2} w^T w\\right\\} \\\\\n",
    "   & = \\frac{\\alpha^{d / 2}}{(2 \\pi)^{d / 2}} \\exp \\left\\{-\\frac{\\alpha}{2} \\left|\\left|w\\right|\\right|^2\\right\\}. \\\\\n",
    "\\end{align}\n",
    "\n",
    "En este caso, podemos usar el parámetro $\\alpha$ para expresar cuanta certeza tenemos de que $w$ está cercano a cero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0591ac",
   "metadata": {},
   "source": [
    "De lo anterior, observamos que:\n",
    "\n",
    "$$\n",
    "\\log p(w) \n",
    "= \\textcolor{blue}{\\log \\frac{\\alpha^{d / 2}}{(2 \\pi)^{d / 2}}} \n",
    "-  \\textcolor{blue}{\\frac{\\alpha}{2} \\left|\\left|w\\right|\\right|^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe418b7",
   "metadata": {},
   "source": [
    "Reemplazando en la expresión anterior y descartando todos los sumandos que no dependen de $w$:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{w}_{MAP} & = \\arg \\max_{w} l(w) + \\log p(w) \\\\\n",
    "              & = \\arg \\max_{w} - \\frac{\\beta}{2} \\left|\\left|y - \\Phi w\\right|\\right|^2 - \\frac{\\alpha}{2} \\left|\\left|w\\right|\\right|^2 \\\\\n",
    "              & = \\arg \\min_{w} \\left|\\left|y - \\Phi w\\right|\\right|^2 + \\underbrace{\\frac{\\alpha}{\\beta}}_{\\lambda} \\left|\\left|w\\right|\\right|^2.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b807d4",
   "metadata": {},
   "source": [
    "Entonces, observamos que la estimación de parámetros por MAP, usando una previa Gaussiana nos conduce a nuestra intuición detrás de **mínimos cuadrados regularizados con norma-$2$ (Ridge)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd162d3",
   "metadata": {},
   "source": [
    "#### Previa de Laplace\n",
    "\n",
    "Otra previa común en este caso, es modelar la incertidumbre en los parámetros como una distribución de Laplace:\n",
    "\n",
    "$$\n",
    "p(w_i) = \\frac{1}{2 b} \\exp\\left(-\\frac{|w_i|}{b}\\right),\n",
    "$$\n",
    "\n",
    "con lo cual, suponiendo que los parámetros son independientes:\n",
    "\n",
    "\\begin{align}\n",
    "p(w) & = \\prod_{i=1}^{d} p(w_i) \\\\\n",
    "     & = \\frac{1}{(2 b)^{d}} \\exp\\left(-\\sum_{i=1}^{d}\\frac{|w_i|}{b}\\right) \\\\\n",
    "     & = \\frac{1}{(2 b)^{d}} \\exp\\left(-\\frac{1}{b} \\sum_{i=1}^{d}|w_i|\\right). \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ebf612",
   "metadata": {},
   "source": [
    "En este caso, observamos que:\n",
    "\n",
    "$$\n",
    "\\log p(w) \n",
    "= \\textcolor{blue}{\\log \\frac{1}{(2 b)^{d}}} \n",
    "- \\textcolor{blue}{\\frac{1}{b} \\sum_{i=1}^{d}|w_i|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bd769f",
   "metadata": {},
   "source": [
    "Con lo cual\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{w}_{MAP} & = \\arg \\min_{w} \\left|\\left|y - \\Phi w\\right|\\right|^2 + \\underbrace{\\frac{1}{\\beta b}}_{\\lambda}  \\sum_{i=1}^{d}|w_i|.\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Entonces, observamos que la estimación de parámetros por MAP, usando una previa de Laplace nos conduce a nuestra intuición detrás de **mínimos cuadrados regularizados con norma-$1$ (Lasso)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74fe902",
   "metadata": {},
   "source": [
    "### III. Conclusiones\n",
    "\n",
    "1. Desde la **perspectiva probabilística**, podemos reinterpretar el problema de ajuste de curvas y recuperar resultados clásicos de forma intuitiva.  \n",
    "\n",
    "2. Los **estimadores de máxima verosimilitud (MLE)** funcionan bien con muchos datos, pero tienden a sufrir de _overfitting_ cuando la muestra es pequeña.  \n",
    "\n",
    "3. Los **estimadores de máxima a posteriori (MAP)** incorporan información previa sobre los parámetros mediante una distribución _prior_, lo que actúa como un mecanismo natural de **regularización**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
